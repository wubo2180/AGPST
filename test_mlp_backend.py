"""
æµ‹è¯• MLP åç«¯è¿ç§»åçš„æ¨¡å‹
éªŒè¯æ¨¡å‹å¯ä»¥æ­£å¸¸åˆå§‹åŒ–å’Œå‰å‘ä¼ æ’­
"""

import torch
import sys
sys.path.append('.')

from basicts.mask.model import AGPSTModel

def test_model_initialization():
    """æµ‹è¯•æ¨¡å‹åˆå§‹åŒ–"""
    print("=" * 60)
    print("æµ‹è¯• 1: æ¨¡å‹åˆå§‹åŒ–")
    print("=" * 60)
    
    model = AGPSTModel(
        num_nodes=358,
        dim=40,
        topK=10,
        in_channel=1,
        embed_dim=96,
        num_heads=4,
        mlp_ratio=4,
        dropout=0.1,
        encoder_depth=4,
        use_denoising=True,
        denoise_type='conv',
        use_advanced_graph=True,
        graph_heads=4,
        pred_len=12  # æ–°å‚æ•°
    )
    
    print("âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼")
    print(f"   - æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    print(f"   - å¯è®­ç»ƒå‚æ•°: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
    return model

def test_forward_pass(model):
    """æµ‹è¯•å‰å‘ä¼ æ’­"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 2: å‰å‘ä¼ æ’­")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    batch_size = 4
    seq_len = 12
    num_nodes = 358
    in_channels = 1
    
    history_data = torch.randn(batch_size, seq_len, num_nodes, in_channels)
    print(f"è¾“å…¥å½¢çŠ¶: {history_data.shape}")
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        prediction = model(history_data)
    
    print(f"è¾“å‡ºå½¢çŠ¶: {prediction.shape}")
    
    # éªŒè¯è¾“å‡ºå½¢çŠ¶
    expected_shape = (batch_size, 12, num_nodes, 1)
    assert prediction.shape == expected_shape, f"æœŸæœ›å½¢çŠ¶ {expected_shape}, å¾—åˆ° {prediction.shape}"
    
    print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼")
    print(f"   - è¾“å…¥: (B={batch_size}, T={seq_len}, N={num_nodes}, C={in_channels})")
    print(f"   - è¾“å‡º: (B={batch_size}, pred_len=12, N={num_nodes}, C=1)")
    print(f"   - é¢„æµ‹å€¼èŒƒå›´: [{prediction.min():.4f}, {prediction.max():.4f}]")
    
    return prediction

def test_different_denoise_modes(model_params):
    """æµ‹è¯•ä¸åŒå»å™ªæ¨¡å¼"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 3: ä¸åŒå»å™ªæ¨¡å¼")
    print("=" * 60)
    
    modes = ['conv', 'attention']
    
    for mode in modes:
        print(f"\næµ‹è¯•å»å™ªæ¨¡å¼: {mode}")
        params = model_params.copy()
        params['denoise_type'] = mode
        
        model = AGPSTModel(**params)
        history_data = torch.randn(2, 12, 358, 1)
        
        with torch.no_grad():
            prediction = model(history_data)
        
        print(f"  âœ… {mode} æ¨¡å¼æ­£å¸¸å·¥ä½œ")
        print(f"     è¾“å‡ºå½¢çŠ¶: {prediction.shape}")

def test_without_denoising(model_params):
    """æµ‹è¯•æ— å»å™ªæ¨¡å¼"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 4: æ— å»å™ªæ¨¡å¼")
    print("=" * 60)
    
    params = model_params.copy()
    params['use_denoising'] = False
    
    model = AGPSTModel(**params)
    history_data = torch.randn(2, 12, 358, 1)
    
    with torch.no_grad():
        prediction = model(history_data)
    
    print(f"âœ… æ— å»å™ªæ¨¡å¼æ­£å¸¸å·¥ä½œ")
    print(f"   è¾“å‡ºå½¢çŠ¶: {prediction.shape}")

def test_gradient_flow():
    """æµ‹è¯•æ¢¯åº¦æµ"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 5: æ¢¯åº¦æµ")
    print("=" * 60)
    
    model = AGPSTModel(
        num_nodes=358,
        dim=40,
        topK=10,
        in_channel=1,
        embed_dim=96,
        num_heads=4,
        mlp_ratio=4,
        dropout=0.1,
        encoder_depth=4,
        use_denoising=True,
        denoise_type='conv',
        use_advanced_graph=True,
        graph_heads=4,
        pred_len=12
    )
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    history_data = torch.randn(2, 12, 358, 1)
    target = torch.randn(2, 12, 358, 1)
    
    # å‰å‘ä¼ æ’­
    prediction = model(history_data)
    
    # è®¡ç®—æŸå¤±
    loss = torch.nn.functional.mse_loss(prediction, target)
    
    # åå‘ä¼ æ’­
    loss.backward()
    
    # æ£€æŸ¥æ¢¯åº¦
    has_grad = sum(1 for p in model.parameters() if p.grad is not None and p.grad.abs().sum() > 0)
    total_params = sum(1 for p in model.parameters() if p.requires_grad)
    
    print(f"âœ… æ¢¯åº¦æµæµ‹è¯•é€šè¿‡")
    print(f"   - æŸå¤±å€¼: {loss.item():.6f}")
    print(f"   - æœ‰æ¢¯åº¦çš„å‚æ•°: {has_grad}/{total_params}")
    print(f"   - å¹³å‡æ¢¯åº¦èŒƒæ•°: {sum(p.grad.norm() for p in model.parameters() if p.grad is not None) / has_grad:.6f}")

def test_different_pred_lengths():
    """æµ‹è¯•ä¸åŒé¢„æµ‹é•¿åº¦"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 6: ä¸åŒé¢„æµ‹é•¿åº¦")
    print("=" * 60)
    
    pred_lengths = [3, 6, 12, 24]
    
    for pred_len in pred_lengths:
        print(f"\næµ‹è¯•é¢„æµ‹é•¿åº¦: {pred_len}")
        
        model = AGPSTModel(
            num_nodes=358,
            dim=40,
            topK=10,
            in_channel=1,
            embed_dim=96,
            num_heads=4,
            mlp_ratio=4,
            dropout=0.1,
            encoder_depth=4,
            pred_len=pred_len  # ä¸åŒçš„é¢„æµ‹é•¿åº¦
        )
        
        history_data = torch.randn(2, 12, 358, 1)
        
        with torch.no_grad():
            prediction = model(history_data)
        
        expected_shape = (2, pred_len, 358, 1)
        assert prediction.shape == expected_shape, f"æœŸæœ› {expected_shape}, å¾—åˆ° {prediction.shape}"
        
        print(f"  âœ… pred_len={pred_len} æ­£å¸¸å·¥ä½œ")
        print(f"     è¾“å‡ºå½¢çŠ¶: {prediction.shape}")

def main():
    print("\n" + "ğŸš€" * 30)
    print("MLP åç«¯è¿ç§»éªŒè¯æµ‹è¯•")
    print("ğŸš€" * 30 + "\n")
    
    # åŸºç¡€å‚æ•°
    model_params = {
        'num_nodes': 358,
        'dim': 40,
        'topK': 10,
        'in_channel': 1,
        'embed_dim': 96,
        'num_heads': 4,
        'mlp_ratio': 4,
        'dropout': 0.1,
        'encoder_depth': 4,
        'use_denoising': True,
        'denoise_type': 'conv',
        'use_advanced_graph': True,
        'graph_heads': 4,
        'pred_len': 12
    }
    
    try:
        # æµ‹è¯• 1: åˆå§‹åŒ–
        model = test_model_initialization()
        
        # æµ‹è¯• 2: å‰å‘ä¼ æ’­
        test_forward_pass(model)
        
        # æµ‹è¯• 3: ä¸åŒå»å™ªæ¨¡å¼
        test_different_denoise_modes(model_params)
        
        # æµ‹è¯• 4: æ— å»å™ªæ¨¡å¼
        test_without_denoising(model_params)
        
        # æµ‹è¯• 5: æ¢¯åº¦æµ
        test_gradient_flow()
        
        # æµ‹è¯• 6: ä¸åŒé¢„æµ‹é•¿åº¦
        test_different_pred_lengths()
        
        # æ€»ç»“
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("=" * 60)
        print("\nâœ… MLP åç«¯è¿ç§»æˆåŠŸï¼")
        print("âœ… æ¨¡å‹å¯ä»¥æ­£å¸¸åˆå§‹åŒ–å’Œå‰å‘ä¼ æ’­")
        print("âœ… æ”¯æŒä¸åŒçš„å»å™ªæ¨¡å¼å’Œé¢„æµ‹é•¿åº¦")
        print("âœ… æ¢¯åº¦æµæ­£å¸¸ï¼Œå¯ä»¥è¿›è¡Œè®­ç»ƒ")
        print("\nä¸‹ä¸€æ­¥: è¿è¡Œå®Œæ•´çš„è®­ç»ƒå®éªŒ")
        
    except Exception as e:
        print("\n" + "=" * 60)
        print("âŒ æµ‹è¯•å¤±è´¥ï¼")
        print("=" * 60)
        print(f"\né”™è¯¯ä¿¡æ¯: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
