"""
äº¤æ›¿æ—¶ç©ºæ¶æ„ - HimNet å¯å‘ç‰ˆæœ¬ (Alternating ST with HimNet Insights)

æ ¸å¿ƒæ”¹è¿›:
1. å¼‚è´¨æ€§èŠ‚ç‚¹åµŒå…¥ (Heterogeneity-Aware Node Embedding)
2. GCN + Transformer æ··åˆç©ºé—´ç¼–ç 
3. æ›´é²æ£’çš„ç‰¹å¾èåˆ

åŸºäº HimNet (KDD'24) çš„è®¾è®¡ç†å¿µ,åŒæ—¶ä¿æŒæˆ‘ä»¬äº¤æ›¿æ¶æ„çš„ä¼˜åŠ¿
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import math


class TemporalEncoder(nn.Module):
    """
    æ—¶é—´ç¼–ç å™¨ - ä¸ Phase 1 ç›¸åŒ
    ä½¿ç”¨ Transformer æ•è·æ—¶é—´ä¾èµ–
    """
    def __init__(self, d_model, num_heads=4, num_layers=2, dropout=0.1):
        super().__init__()
        self.d_model = d_model
        
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=num_heads,
            dim_feedforward=d_model * 4,
            dropout=dropout,
            batch_first=True,
            activation='gelu'
        )
        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        self.norm = nn.LayerNorm(d_model)
        
    def forward(self, x):
        B, N, T, D = x.shape
        x_flat = x.reshape(B * N, T, D)
        temporal_features = self.encoder(x_flat)
        temporal_features = self.norm(temporal_features)
        return temporal_features.reshape(B, N, T, D)


class GraphConvLayer(nn.Module):
    """
    å›¾å·ç§¯å±‚ - å€Ÿé‰´ HimNet çš„ GCN è®¾è®¡
    ä½¿ç”¨é‚»æ¥çŸ©é˜µèšåˆé‚»å±…ä¿¡æ¯
    """
    def __init__(self, in_dim, out_dim, bias=True):
        super().__init__()
        self.in_dim = in_dim
        self.out_dim = out_dim
        
        self.weight = nn.Parameter(torch.FloatTensor(in_dim, out_dim))
        if bias:
            self.bias = nn.Parameter(torch.FloatTensor(out_dim))
        else:
            self.register_parameter('bias', None)
        
        self.reset_parameters()
    
    def reset_parameters(self):
        stdv = 1. / math.sqrt(self.weight.size(1))
        self.weight.data.uniform_(-stdv, stdv)
        if self.bias is not None:
            self.bias.data.uniform_(-stdv, stdv)
    
    def forward(self, x, adj):
        """
        Args:
            x: (B*T, N, D) - èŠ‚ç‚¹ç‰¹å¾
            adj: (N, N) - å½’ä¸€åŒ–é‚»æ¥çŸ©é˜µ
        Returns:
            out: (B*T, N, D) - å›¾å·ç§¯åçš„ç‰¹å¾
        """
        # 1. ç‰¹å¾å˜æ¢: X @ W
        support = torch.matmul(x, self.weight)  # (B*T, N, D_out)
        
        # 2. é‚»å±…èšåˆ: A @ (X @ W)
        output = torch.matmul(adj, support)  # (N, N) @ (B*T, N, D_out)
        
        if self.bias is not None:
            output = output + self.bias
        
        return output


class HeterogeneousSpatialEncoder(nn.Module):
    """
    å¼‚è´¨æ€§æ„ŸçŸ¥çš„ç©ºé—´ç¼–ç å™¨ - æ ¸å¿ƒåˆ›æ–°!
    
    è®¾è®¡ç†å¿µ (å€Ÿé‰´ HimNet):
    1. æ¯ä¸ªèŠ‚ç‚¹æœ‰ç‹¬ç«‹çš„å…ƒåµŒå…¥ (æ•è·èŠ‚ç‚¹å¼‚è´¨æ€§)
    2. æ··åˆ GCN + Transformer (ç‰©ç†å…ˆéªŒ + è¯­ä¹‰å­¦ä¹ )
    3. èŠ‚ç‚¹åµŒå…¥åŠ¨æ€è°ƒåˆ¶æ³¨æ„åŠ›æƒé‡
    
    è¾“å…¥: (B, N, T, D)
    è¾“å‡º: (B, N, T, D)
    """
    def __init__(self, num_nodes, d_model, adj_mx=None, d_meta=64, 
                 num_heads=4, num_layers=2, dropout=0.1, use_gcn=True):
        super().__init__()
        self.num_nodes = num_nodes
        self.d_model = d_model
        self.use_gcn = use_gcn
        
        # ğŸ”¥ åˆ›æ–° 1: èŠ‚ç‚¹å¼‚è´¨æ€§åµŒå…¥
        self.node_emb = nn.Parameter(torch.randn(num_nodes, d_meta))
        
        # å…ƒåµŒå…¥ â†’ Query/Key åç½® (ä¸ºä¸åŒèŠ‚ç‚¹ç”Ÿæˆä¸åŒæ³¨æ„åŠ›æ¨¡å¼)
        self.meta_q = nn.Linear(d_meta, d_model)
        self.meta_k = nn.Linear(d_meta, d_model)
        
        # ğŸ”¥ åˆ›æ–° 2: GCN åˆ†æ”¯ (åˆ©ç”¨ç‰©ç†é‚»æ¥å…³ç³»)
        if use_gcn and adj_mx is not None:
            self.gcn_layers = nn.ModuleList([
                GraphConvLayer(d_model, d_model) for _ in range(2)
            ])
            self.gcn_norm = nn.LayerNorm(d_model)
            
            # å½’ä¸€åŒ–é‚»æ¥çŸ©é˜µ (åªåšä¸€æ¬¡)
            self.register_buffer('adj_mx', self._normalize_adj(adj_mx))
        else:
            self.gcn_layers = None
        
        # ğŸ”¥ åˆ›æ–° 3: Transformer åˆ†æ”¯ (å­¦ä¹ éšå¼è¯­ä¹‰å…³ç³»)
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=num_heads,
            dim_feedforward=d_model * 4,
            dropout=dropout,
            batch_first=True,
            activation='gelu'
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        self.trans_norm = nn.LayerNorm(d_model)
        
        # èåˆ GCN + Transformer
        if use_gcn and adj_mx is not None:
            self.fusion = nn.Sequential(
                nn.Linear(d_model * 2, d_model),
                nn.GELU(),
                nn.Dropout(dropout)
            )
        
    def _normalize_adj(self, adj_mx):
        """
        å¯¹ç§°å½’ä¸€åŒ–: D^(-0.5) @ A @ D^(-0.5)
        """
        adj_mx = adj_mx + torch.eye(adj_mx.size(0), device=adj_mx.device)  # æ·»åŠ è‡ªç¯
        rowsum = adj_mx.sum(1)
        d_inv_sqrt = torch.pow(rowsum, -0.5).flatten()
        d_inv_sqrt[torch.isinf(d_inv_sqrt)] = 0.
        d_mat_inv_sqrt = torch.diag(d_inv_sqrt)
        return d_mat_inv_sqrt @ adj_mx @ d_mat_inv_sqrt
    
    def forward(self, x):
        """
        Args:
            x: (B, N, T, D)
        Returns:
            out: (B, N, T, D) - ç©ºé—´ç¼–ç åçš„ç‰¹å¾
        """
        B, N, T, D = x.shape
        
        # ç”ŸæˆèŠ‚ç‚¹ç‰¹å®šçš„ Q/K åç½®
        node_q_bias = self.meta_q(self.node_emb)  # (N, D)
        node_k_bias = self.meta_k(self.node_emb)  # (N, D)
        
        # é‡å¡‘: (B, N, T, D) â†’ (B*T, N, D)
        x_flat = x.permute(0, 2, 1, 3).reshape(B * T, N, D)
        
        # === Transformer åˆ†æ”¯ ===
        # æ·»åŠ èŠ‚ç‚¹ç‰¹å®šçš„åç½®
        x_trans = x_flat + node_q_bias.unsqueeze(0)  # å¹¿æ’­åˆ° (B*T, N, D)
        x_trans = self.transformer(x_trans)
        x_trans = self.trans_norm(x_trans)
        
        # === GCN åˆ†æ”¯ (å¦‚æœå¯ç”¨) ===
        if self.use_gcn and self.gcn_layers is not None:
            x_gcn = x_flat
            for gcn_layer in self.gcn_layers:
                x_gcn = F.relu(gcn_layer(x_gcn, self.adj_mx))
            x_gcn = self.gcn_norm(x_gcn)
            
            # èåˆä¸¤æ¡è·¯å¾„
            x_fused = torch.cat([x_trans, x_gcn], dim=-1)  # (B*T, N, 2D)
            spatial_features = self.fusion(x_fused)  # (B*T, N, D)
        else:
            spatial_features = x_trans
        
        # é‡å¡‘å›åŸå§‹å½¢çŠ¶: (B*T, N, D) â†’ (B, N, T, D)
        spatial_features = spatial_features.reshape(B, T, N, D).permute(0, 2, 1, 3)
        
        return spatial_features


class ImprovedFusionLayer(nn.Module):
    """
    æ”¹è¿›çš„èåˆå±‚ - æ›´é²æ£’çš„ç‰¹å¾èåˆ
    
    å€Ÿé‰´ HimNet çš„é—¨æ§æœºåˆ¶ + Cross-Attention
    """
    def __init__(self, d_model, num_heads=4, dropout=0.1, fusion_type='gated_cross_attn'):
        super().__init__()
        self.d_model = d_model
        self.fusion_type = fusion_type
        
        if fusion_type == 'gated_cross_attn':
            # Cross-Attention: æ—¶é—´ç‰¹å¾ attend to ç©ºé—´ç‰¹å¾
            self.cross_attn = nn.MultiheadAttention(
                embed_dim=d_model,
                num_heads=num_heads,
                dropout=dropout,
                batch_first=True
            )
            
            # é—¨æ§æœºåˆ¶
            self.gate = nn.Sequential(
                nn.Linear(d_model * 2, d_model),
                nn.Sigmoid()
            )
            
            self.fusion_proj = nn.Sequential(
                nn.Linear(d_model * 2, d_model),
                nn.GELU(),
                nn.Dropout(dropout)
            )
            
        elif fusion_type == 'cross_attn':
            self.cross_attn = nn.MultiheadAttention(
                embed_dim=d_model,
                num_heads=num_heads,
                dropout=dropout,
                batch_first=True
            )
            self.norm = nn.LayerNorm(d_model)
            
        else:  # 'gated'
            self.gate = nn.Sequential(
                nn.Linear(d_model * 2, d_model),
                nn.Sigmoid()
            )
            self.fusion_proj = nn.Linear(d_model * 2, d_model)
        
        self.norm = nn.LayerNorm(d_model)
    
    def forward(self, temporal_feat, spatial_feat):
        """
        Args:
            temporal_feat: (B, N, T, D)
            spatial_feat: (B, N, T, D)
        Returns:
            fused: (B, N, T, D)
        """
        B, N, T, D = temporal_feat.shape
        
        if self.fusion_type == 'gated_cross_attn':
            # é‡å¡‘ç”¨äº Cross-Attention
            temp_flat = temporal_feat.reshape(B * N, T, D)
            spat_flat = spatial_feat.reshape(B * N, T, D)
            
            # Cross-Attention: temporal as Query, spatial as Key/Value
            attn_out, _ = self.cross_attn(temp_flat, spat_flat, spat_flat)
            attn_out = attn_out.reshape(B, N, T, D)
            
            # é—¨æ§èåˆ
            concat = torch.cat([temporal_feat, attn_out], dim=-1)
            gate = self.gate(concat)
            fused = self.fusion_proj(concat) * gate + temporal_feat * (1 - gate)
            
        elif self.fusion_type == 'cross_attn':
            temp_flat = temporal_feat.reshape(B * N, T, D)
            spat_flat = spatial_feat.reshape(B * N, T, D)
            
            attn_out, _ = self.cross_attn(temp_flat, spat_flat, spat_flat)
            fused = self.norm(temp_flat + attn_out)
            fused = fused.reshape(B, N, T, D)
            
        else:  # 'gated'
            concat = torch.cat([temporal_feat, spatial_feat], dim=-1)
            gate = self.gate(concat)
            fused = self.fusion_proj(concat) * gate + temporal_feat * (1 - gate)
        
        return self.norm(fused)


class STDecoder(nn.Module):
    """
    æ—¶ç©ºè§£ç å™¨ - ä¸ Phase 1 ç›¸åŒ
    å°†èåˆç‰¹å¾è§£ç å›æ—¶é—´å’Œç©ºé—´ç»´åº¦
    """
    def __init__(self, d_model, num_heads=4, num_layers=2, dropout=0.1):
        super().__init__()
        
        decoder_layer = nn.TransformerDecoderLayer(
            d_model=d_model,
            nhead=num_heads,
            dim_feedforward=d_model * 4,
            dropout=dropout,
            batch_first=True,
            activation='gelu'
        )
        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)
        
        # æ—¶ç©ºç‰¹å¾åˆ†ç¦»æŠ•å½±
        self.temporal_proj = nn.Linear(d_model, d_model)
        self.spatial_proj = nn.Linear(d_model, d_model)
        
        self.norm = nn.LayerNorm(d_model)
    
    def forward(self, fused_features, num_queries=24):
        """
        Args:
            fused_features: (B, N, T, D) - èåˆåçš„æ—¶ç©ºç‰¹å¾
            num_queries: int - è§£ç å™¨æŸ¥è¯¢æ•°é‡
        Returns:
            temporal_decoded: (B, N, T, D)
            spatial_decoded: (B, N, T, D)
        """
        B, N, T, D = fused_features.shape
        
        # åˆ›å»ºå¯å­¦ä¹ çš„æŸ¥è¯¢å‘é‡
        queries = fused_features.mean(dim=(1, 2), keepdim=True).expand(B, N, T, D)
        
        # é‡å¡‘ç”¨äº Transformer Decoder
        queries_flat = queries.reshape(B * N, T, D)
        memory_flat = fused_features.reshape(B * N, T, D)
        
        # è§£ç 
        decoded = self.decoder(queries_flat, memory_flat)
        decoded = self.norm(decoded)
        decoded = decoded.reshape(B, N, T, D)
        
        # åˆ†ç¦»æ—¶ç©ºç‰¹å¾
        temporal_decoded = self.temporal_proj(decoded)
        spatial_decoded = self.spatial_proj(decoded)
        
        return temporal_decoded, spatial_decoded


class AlternatingSTModel_HimNet(nn.Module):
    """
    äº¤æ›¿æ—¶ç©ºæ¨¡å‹ - HimNet å¯å‘ç‰ˆæœ¬
    
    æ ¸å¿ƒæ”¹è¿›:
    1. âœ… å¼‚è´¨æ€§èŠ‚ç‚¹åµŒå…¥ (æ¯ä¸ªèŠ‚ç‚¹æœ‰ç‹¬ç«‹å…ƒåµŒå…¥)
    2. âœ… GCN + Transformer æ··åˆç©ºé—´ç¼–ç 
    3. âœ… æ”¹è¿›çš„é—¨æ§èåˆæœºåˆ¶
    4. âœ… ä¿æŒäº¤æ›¿æ¶æ„çš„ä¼˜åŠ¿ (ä¿¡æ¯æµåŠ¨)
    
    æ¶æ„:
        Input â†’ Temporal Enc1 â†’ Spatial Enc1 (Heterogeneous + GCN) â†’ Fusion1 â†’
        Decoder â†’ Temporal Enc2 â†’ Spatial Enc2 (Heterogeneous + GCN) â†’ Fusion2 â†’ Output
    """
    def __init__(
        self,
        num_nodes,
        in_channel,
        embed_dim,
        output_len=12,
        input_len=12,
        adj_mx=None,
        num_heads=4,
        temporal_depth_1=1,
        spatial_depth_1=1,
        temporal_depth_2=3,
        spatial_depth_2=3,
        decoder_depth=2,
        dropout=0.1,
        fusion_type='gated_cross_attn',
        use_gcn=True,
        d_meta=64
    ):
        super().__init__()
        
        self.num_nodes = num_nodes
        self.input_len = input_len
        self.output_len = output_len
        self.embed_dim = embed_dim
        
        # è¾“å…¥åµŒå…¥
        self.input_proj = nn.Linear(in_channel, embed_dim)
        
        # ä½ç½®ç¼–ç 
        self.pos_encoding = nn.Parameter(torch.randn(1, num_nodes, input_len, embed_dim))
        
        # === Stage 1: åˆæ­¥ç‰¹å¾æå– ===
        self.temporal_encoder_1 = TemporalEncoder(
            embed_dim, num_heads, temporal_depth_1, dropout
        )
        
        self.spatial_encoder_1 = HeterogeneousSpatialEncoder(
            num_nodes, embed_dim, adj_mx, d_meta, 
            num_heads, spatial_depth_1, dropout, use_gcn
        )
        
        self.fusion_1 = ImprovedFusionLayer(
            embed_dim, num_heads, dropout, fusion_type
        )
        
        # è§£ç å™¨
        self.decoder = STDecoder(embed_dim, num_heads, decoder_depth, dropout)
        
        # === Stage 2: ç²¾ç»†åŒ–å»ºæ¨¡ ===
        self.temporal_encoder_2 = TemporalEncoder(
            embed_dim, num_heads, temporal_depth_2, dropout
        )
        
        self.spatial_encoder_2 = HeterogeneousSpatialEncoder(
            num_nodes, embed_dim, adj_mx, d_meta,
            num_heads, spatial_depth_2, dropout, use_gcn
        )
        
        self.fusion_2 = ImprovedFusionLayer(
            embed_dim, num_heads, dropout, fusion_type
        )
        
        # è¾“å‡ºæŠ•å½±
        self.output_proj = nn.Sequential(
            nn.Linear(embed_dim, embed_dim // 2),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(embed_dim // 2, in_channel)
        )
        
        self._init_weights()
    
    def _init_weights(self):
        """æƒé‡åˆå§‹åŒ–"""
        for p in self.parameters():
            if p.dim() > 1:
                nn.init.xavier_uniform_(p)
    
    def forward(self, history_data, **kwargs):
        """
        Args:
            history_data: (B, T, N, C) - å†å²æ•°æ®
        Returns:
            prediction: (B, T_pred, N, C)
        """
        # è½¬æ¢ç»´åº¦: (B, T, N, C) â†’ (B, N, T, C)
        x = history_data.permute(0, 2, 1, 3)
        B, N, T, C = x.shape
        
        # è¾“å…¥åµŒå…¥
        x = self.input_proj(x)  # (B, N, T, D)
        x = x + self.pos_encoding[:, :, :T, :]  # ä½ç½®ç¼–ç 
        
        # === Stage 1: åˆæ­¥ç¼–ç  ===
        temp_out_1 = self.temporal_encoder_1(x)
        spat_out_1 = self.spatial_encoder_1(temp_out_1)
        fused_1 = self.fusion_1(temp_out_1, spat_out_1)
        
        # è§£ç 
        temporal_decoded, spatial_decoded = self.decoder(fused_1)
        
        # === Stage 2: ç²¾ç»†åŒ–ç¼–ç  ===
        # ä½¿ç”¨è§£ç ç»“æœä½œä¸ºè¾“å…¥
        stage2_input = temporal_decoded + spatial_decoded
        
        temp_out_2 = self.temporal_encoder_2(stage2_input)
        spat_out_2 = self.spatial_encoder_2(temp_out_2)
        final_features = self.fusion_2(temp_out_2, spat_out_2)
        
        # è¾“å‡ºæŠ•å½±
        output = self.output_proj(final_features)  # (B, N, T, C)
        
        # è½¬æ¢å›åŸå§‹ç»´åº¦: (B, N, T, C) â†’ (B, T, N, C)
        output = output.permute(0, 2, 1, 3)
        
        return output
