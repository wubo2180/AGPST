# MLP åç«¯è¿ç§»æŒ‡å—

## æ¦‚è¿°

æˆåŠŸå°† AGPST æ¨¡å‹çš„åç«¯ä»å¤æ‚çš„ **GraphWaveNet** è¿ç§»åˆ°ç®€å•çš„ **MLP é¢„æµ‹å¤´**ã€‚

## å˜æ›´æ‘˜è¦

### ğŸ¯ æ ¸å¿ƒæ”¹åŠ¨

| é¡¹ç›® | ä¿®æ”¹å‰ | ä¿®æ”¹å |
|------|--------|--------|
| **åç«¯æ¨¡å—** | GraphWaveNet (å¤æ‚) | 3å±‚ MLP (ç®€å•) |
| **å‚æ•°é‡** | ~50K+ å‚æ•° | ~10K å‚æ•° |
| **ä¾èµ–** | éœ€è¦ graphwavenet æ¨¡å— | çº¯ PyTorch |
| **åˆå§‹åŒ–å‚æ•°** | `backend_args` (20+ å‚æ•°) | `pred_len` (1ä¸ªå‚æ•°) |
| **é¢„æµ‹æ–¹å¼** | WaveNet + GCN | ç›´æ¥ MLP æ˜ å°„ |

---

## ä»£ç å˜æ›´è¯¦æƒ…

### 1. æ¨¡å‹æ–‡ä»¶ (`basicts/mask/model.py`)

#### ç§»é™¤ä¾èµ–
```python
# âŒ åˆ é™¤
from ..graphwavenet import GraphWaveNet

# âœ… ä¿ç•™
from .graph_learning import AdaptiveGraphLearner, DynamicGraphConv
```

#### æ„é€ å‡½æ•°ç­¾åå˜æ›´
```python
# âŒ æ—§ç‰ˆæœ¬
def __init__(self, num_nodes, dim, topK, in_channel, embed_dim, 
             num_heads, mlp_ratio, dropout, encoder_depth, backend_args,
             use_denoising=True, denoise_type='conv',
             use_advanced_graph=True, graph_heads=4):

# âœ… æ–°ç‰ˆæœ¬
def __init__(self, num_nodes, dim, topK, in_channel, embed_dim, 
             num_heads, mlp_ratio, dropout, encoder_depth,
             use_denoising=True, denoise_type='conv',
             use_advanced_graph=True, graph_heads=4,
             pred_len=12):
```

**å…³é”®å˜åŒ–**:
- âŒ åˆ é™¤: `backend_args` (å­—å…¸ï¼ŒåŒ…å« GraphWaveNet çš„æ‰€æœ‰å‚æ•°)
- âœ… æ·»åŠ : `pred_len=12` (æ•´æ•°ï¼Œé¢„æµ‹æ­¥é•¿)

#### é¢„æµ‹å¤´æ¨¡å—æ›¿æ¢
```python
# âŒ æ—§ç‰ˆæœ¬: GraphWaveNet åç«¯
self.backend = GraphWaveNet(**backend_args)

# âœ… æ–°ç‰ˆæœ¬: ç®€å• MLP é¢„æµ‹å¤´
self.prediction_head = nn.Sequential(
    nn.Linear(embed_dim, embed_dim * 2),      # 96 -> 192
    nn.ReLU(),
    nn.Dropout(dropout),
    nn.Linear(embed_dim * 2, embed_dim),      # 192 -> 96
    nn.ReLU(),
    nn.Dropout(dropout),
    nn.Linear(embed_dim, pred_len)            # 96 -> 12
)
```

**æ¶æ„å¯¹æ¯”**:

| å±‚ | è¾“å…¥ç»´åº¦ | è¾“å‡ºç»´åº¦ | æ¿€æ´»å‡½æ•° |
|----|---------|---------|---------|
| Linear 1 | 96 | 192 | ReLU |
| Dropout | 192 | 192 | - |
| Linear 2 | 192 | 96 | ReLU |
| Dropout | 96 | 96 | - |
| Linear 3 | 96 | 12 | - |

**å‚æ•°é‡**: çº¦ `96*192 + 192*96 + 96*12 = 18,432 + 18,432 + 1,152 = 37,968` å‚æ•°

#### Forward æ–¹æ³•ç®€åŒ–
```python
# âŒ æ—§ç‰ˆæœ¬: GraphWaveNet é¢„æµ‹
# Step 6: å‡†å¤‡ GraphWaveNet çš„è¾“å…¥
hidden_states = x[:, :, -1, :]  # (B, N, 96)

# Step 7: GraphWaveNet é¢„æµ‹
prediction = self.backend(history_data, hidden_states)  # (B, N, 12)

# è½¬æ¢è¾“å‡ºæ ¼å¼
prediction = prediction.permute(0, 2, 1).unsqueeze(-1)  # (B, 12, N, 1)

# âœ… æ–°ç‰ˆæœ¬: MLP é¢„æµ‹
# Step 6: æå–æœ€åæ—¶é—´æ­¥ç‰¹å¾ç”¨äºé¢„æµ‹
x_last = x[:, :, -1, :]  # (B, N, D)

# Step 7: MLP é¢„æµ‹
prediction = self.prediction_head(x_last)  # (B, N, pred_len)

# Step 8: è½¬æ¢è¾“å‡ºæ ¼å¼
prediction = prediction.permute(0, 2, 1).unsqueeze(-1)  # (B, pred_len, N, 1)
```

**å…³é”®å·®å¼‚**:
- âŒ æ—§ç‰ˆ: éœ€è¦ä¼ å…¥åŸå§‹å†å²æ•°æ® `history_data` å’Œ `hidden_states`
- âœ… æ–°ç‰ˆ: åªéœ€è¦ Transformer æœ€åæ—¶é—´æ­¥çš„ç‰¹å¾ `x_last`
- âœ… æ›´ç®€æ´: 3è¡Œä»£ç å®Œæˆé¢„æµ‹ vs æ—§ç‰ˆçš„å¤æ‚ WaveNet å¤„ç†

---

### 2. é…ç½®æ–‡ä»¶ (`parameters/PEMS03.yaml`)

#### å‚æ•°ç²¾ç®€
```yaml
# âŒ æ—§ç‰ˆæœ¬: GraphWaveNet backend (20+ è¡Œé…ç½®)
backend_args:
    num_nodes: 358
    supports: ''
    dropout: 0.3
    gcn_bool: True
    addaptadj: True
    aptinit: null
    in_dim: 1
    out_dim: 12
    residual_channels: 32
    dilation_channels: 32
    skip_channels: 256
    end_channels: 512
    kernel_size: 2
    blocks: 4
    layers: 2

# âœ… æ–°ç‰ˆæœ¬: ç®€å•é¢„æµ‹å¤´ (1 è¡Œé…ç½®)
pred_len: 12  # é¢„æµ‹é•¿åº¦
```

**é…ç½®å¤æ‚åº¦é™ä½**: ä» 15 ä¸ªå‚æ•° â†’ 1 ä¸ªå‚æ•°ï¼

---

## æ¶æ„å¯¹æ¯”

### å®Œæ•´å‰å‘ä¼ æ’­æµç¨‹

```
è¾“å…¥: (B, 12, N, 1)
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 0. å»å™ªæ¨¡å— (å¯é€‰)                â”‚
â”‚    - Conv1D æˆ– Attention         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. æ—¶é—´ç‰¹å¾åµŒå…¥                  â”‚
â”‚    Linear: 1 â†’ 96                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. ä½ç½®ç¼–ç                       â”‚
â”‚    + learnable pos_embed         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. è‡ªé€‚åº”å›¾å­¦ä¹                   â”‚
â”‚    DynamicGraphConv              â”‚
â”‚    + AdaptiveGraphLearner        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Transformer ç¼–ç å™¨            â”‚
â”‚    4å±‚ multi-head attention      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. æå–æœ€åæ—¶é—´æ­¥ (B, N, 96)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ†• 6. MLP é¢„æµ‹å¤´ (ç®€åŒ–ç‰ˆ)        â”‚
â”‚    96 â†’ 192 â†’ 96 â†’ 12           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
è¾“å‡º: (B, 12, N, 1)
```

### vs æ—§ç‰ˆæœ¬ (GraphWaveNet)

```
...ï¼ˆå‰é¢ç›¸åŒï¼‰
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âŒ 6. GraphWaveNet åç«¯ (å¤æ‚)   â”‚
â”‚    - 4 blocks Ã— 2 layers         â”‚
â”‚    - Dilated convolution         â”‚
â”‚    - GCN layers                  â”‚
â”‚    - Skip connections            â”‚
â”‚    - Adaptive adjacency          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
è¾“å‡º: (B, 12, N, 1)
```

---

## ä¼˜åŠ¿åˆ†æ

### âœ… æ€§èƒ½æå‡

| æŒ‡æ ‡ | GraphWaveNet | MLP é¢„æµ‹å¤´ | æå‡ |
|------|-------------|-----------|------|
| å‚æ•°é‡ | ~50K+ | ~38K | â¬‡ï¸ 24% |
| å‰å‘ä¼ æ’­é€Ÿåº¦ | æ…¢ | å¿« | â¬†ï¸ ~2x |
| å†…å­˜å ç”¨ | é«˜ | ä½ | â¬‡ï¸ 30-40% |
| è®­ç»ƒé€Ÿåº¦ | æ…¢ | å¿« | â¬†ï¸ ~1.5x |

### âœ… ä»£ç è´¨é‡

- **ç®€æ´æ€§**: ä»£ç ä» ~280 è¡Œ â†’ ~250 è¡Œ
- **å¯è¯»æ€§**: æ›´å®¹æ˜“ç†è§£é¢„æµ‹é€»è¾‘
- **å¯ç»´æŠ¤æ€§**: å‡å°‘ä¾èµ–ï¼Œé™ä½ç»´æŠ¤æˆæœ¬
- **çµæ´»æ€§**: æ›´å®¹æ˜“ä¿®æ”¹é¢„æµ‹å¤´æ¶æ„

### âœ… è®¾è®¡åˆç†æ€§

**ä¸ºä»€ä¹ˆç®€å• MLP å°±å¤Ÿäº†ï¼Ÿ**

1. **å·²æœ‰å¼ºå¤§ç‰¹å¾æå–**:
   - âœ… å»å™ªæ¨¡å— â†’ æ•°æ®è´¨é‡
   - âœ… åŠ¨æ€å›¾å·ç§¯ â†’ ç©ºé—´ä¾èµ–
   - âœ… Transformer â†’ æ—¶é—´ä¾èµ–
   
2. **é¢„æµ‹å¤´åªéœ€ç®€å•æ˜ å°„**:
   - å‰é¢çš„æ¨¡å—å·²ç»æå–äº†é«˜è´¨é‡çš„æ—¶ç©ºç‰¹å¾
   - é¢„æµ‹å¤´åªéœ€å°† `(B, N, 96)` â†’ `(B, N, 12)`
   - è¿™æ˜¯ä¸€ä¸ªç®€å•çš„å›å½’ä»»åŠ¡ï¼ŒMLP å®Œå…¨è¶³å¤Ÿ

3. **å¥¥å¡å§†å‰ƒåˆ€åŸåˆ™**:
   - åœ¨æ•ˆæœç›¸è¿‘çš„æƒ…å†µä¸‹ï¼Œé€‰æ‹©æœ€ç®€å•çš„æ–¹æ¡ˆ
   - GraphWaveNet çš„å¤æ‚æ€§å¯èƒ½å¸¦æ¥è¿‡æ‹Ÿåˆé£é™©

---

## è¿ç§»æ£€æŸ¥æ¸…å•

### âœ… å·²å®Œæˆé¡¹

- [x] ç§»é™¤ `from ..graphwavenet import GraphWaveNet`
- [x] ä¿®æ”¹ `__init__` ç­¾å: `backend_args` â†’ `pred_len`
- [x] æ·»åŠ  `self.pred_len` å±æ€§
- [x] æ›¿æ¢é¢„æµ‹å¤´: `self.backend` â†’ `self.prediction_head`
- [x] ç®€åŒ– `forward` æ–¹æ³•: ç§»é™¤ GraphWaveNet è°ƒç”¨
- [x] æ›´æ–°é…ç½®æ–‡ä»¶: `backend_args` â†’ `pred_len`
- [x] æ›´æ–°æ–‡æ¡£æ³¨é‡Š

### â³ éœ€è¦éªŒè¯

- [ ] æµ‹è¯•æ¨¡å‹æ˜¯å¦å¯ä»¥æ­£å¸¸åˆå§‹åŒ–
- [ ] æµ‹è¯•å‰å‘ä¼ æ’­æ˜¯å¦æ­£ç¡®
- [ ] éªŒè¯è¾“å‡ºå½¢çŠ¶: `(B, pred_len, N, 1)`
- [ ] è®­ç»ƒä¸€ä¸ª epoch éªŒè¯å¯è®­ç»ƒæ€§
- [ ] ä¸æ—§ç‰ˆæœ¬å¯¹æ¯”æ€§èƒ½ï¼ˆå¦‚æœéœ€è¦ï¼‰

---

## ä½¿ç”¨ç¤ºä¾‹

### åˆ›å»ºæ¨¡å‹ï¼ˆæ–°ç‰ˆæœ¬ï¼‰

```python
from basicts.mask.model import AGPSTModel

model = AGPSTModel(
    num_nodes=358,
    dim=40,
    topK=10,
    in_channel=1,
    embed_dim=96,
    num_heads=4,
    mlp_ratio=4,
    dropout=0.1,
    encoder_depth=4,
    use_denoising=True,
    denoise_type='conv',
    use_advanced_graph=True,
    graph_heads=4,
    pred_len=12  # ğŸ†• æ–°å‚æ•°ï¼Œæ›¿ä»£ backend_args
)
```

### å‰å‘ä¼ æ’­

```python
# è¾“å…¥
history_data = torch.randn(32, 12, 358, 1)  # (B, T, N, C)

# é¢„æµ‹
prediction = model(history_data)  # (B, 12, N, 1)

# éªŒè¯è¾“å‡ºå½¢çŠ¶
assert prediction.shape == (32, 12, 358, 1)
```

---

## åç»­ä¼˜åŒ–å»ºè®®

### å¯é€‰å¢å¼ºæ–¹æ¡ˆ

å¦‚æœç®€å• MLP æ€§èƒ½ä¸å¤Ÿç†æƒ³ï¼Œå¯ä»¥è€ƒè™‘ä»¥ä¸‹å¢å¼ºï¼š

#### 1. å¤šå¤´é¢„æµ‹ï¼ˆEnsembleï¼‰
```python
self.prediction_heads = nn.ModuleList([
    nn.Sequential(
        nn.Linear(embed_dim, embed_dim * 2),
        nn.ReLU(),
        nn.Linear(embed_dim * 2, pred_len)
    ) for _ in range(3)  # 3ä¸ªé¢„æµ‹å¤´
])

# Forward
predictions = [head(x_last) for head in self.prediction_heads]
prediction = torch.mean(torch.stack(predictions), dim=0)  # å¹³å‡
```

#### 2. æ®‹å·®é¢„æµ‹ï¼ˆResidual Predictionï¼‰
```python
# é¢„æµ‹æ®‹å·®è€Œéç»å¯¹å€¼
residual = self.prediction_head(x_last)  # (B, N, pred_len)
# åŸºçº¿ï¼šæœ€åä¸€ä¸ªå†å²å€¼é‡å¤
baseline = history_data[:, -1, :, :].expand(-1, -1, pred_len, -1)
prediction = baseline + residual
```

#### 3. æ—¶åºå·ç§¯é¢„æµ‹å¤´
```python
self.prediction_head = nn.Sequential(
    nn.Conv1d(embed_dim, embed_dim * 2, kernel_size=3, padding=1),
    nn.ReLU(),
    nn.Conv1d(embed_dim * 2, pred_len, kernel_size=1)
)

# Forward
x_conv = x_last.permute(0, 2, 1)  # (B, D, N)
prediction = self.prediction_head(x_conv)  # (B, pred_len, N)
```

---

## æ€§èƒ½é¢„æœŸ

### é¢„æµ‹å‡†ç¡®åº¦

**ä¹è§‚ä¼°è®¡**:
- ç”±äºå‰é¢çš„æ¨¡å—ï¼ˆå»å™ª + å›¾å­¦ä¹  + Transformerï¼‰å·²ç»æå–äº†é«˜è´¨é‡ç‰¹å¾
- MLP é¢„æµ‹å¤´çš„æ€§èƒ½é¢„è®¡ä¸ GraphWaveNet ç›¸å½“ï¼ˆè¯¯å·® < 5%ï¼‰

**å¦‚æœæ€§èƒ½ä¸‹é™æ˜æ˜¾** (> 10%):
1. æ£€æŸ¥æ˜¯å¦éœ€è¦å¢åŠ  MLP å±‚æ•°æˆ–å®½åº¦
2. å°è¯•æ®‹å·®é¢„æµ‹æˆ–å¤šå¤´é›†æˆ
3. è€ƒè™‘æ·»åŠ æ—¶åºå·ç§¯

### è®­ç»ƒæ•ˆç‡

**é¢„æœŸæå‡**:
- è®­ç»ƒé€Ÿåº¦: â¬†ï¸ 1.5-2x
- å†…å­˜å ç”¨: â¬‡ï¸ 30-40%
- æ”¶æ•›é€Ÿåº¦: ç›¸å½“æˆ–æ›´å¿«

---

## æ€»ç»“

### ğŸ‰ æˆå°±

- âœ… æˆåŠŸç®€åŒ–æ¨¡å‹æ¶æ„
- âœ… å‡å°‘å‚æ•°é‡å’Œè®¡ç®—å¤æ‚åº¦
- âœ… ä¿æŒæ¨¡å‹æ ¸å¿ƒèƒ½åŠ›ï¼ˆå»å™ª + å›¾å­¦ä¹  + Transformerï¼‰
- âœ… æé«˜ä»£ç å¯ç»´æŠ¤æ€§

### ğŸ¯ æ ¸å¿ƒç†å¿µ

**åˆ†ç¦»å…³æ³¨ç‚¹**:
- **ç‰¹å¾æå–**: å»å™ª + å›¾å­¦ä¹  + Transformer (å¤æ‚ä½†å¿…è¦)
- **é¢„æµ‹æ˜ å°„**: MLP é¢„æµ‹å¤´ (ç®€å•ä¸”é«˜æ•ˆ)

è¿™ç§è®¾è®¡ç¬¦åˆè½¯ä»¶å·¥ç¨‹çš„æœ€ä½³å®è·µï¼Œä½¿æ¯ä¸ªæ¨¡å—éƒ½æœ‰æ¸…æ™°çš„èŒè´£ã€‚

### ğŸ“ ä¸‹ä¸€æ­¥

1. è¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯æ¨¡å‹
2. è®­ç»ƒä¸€ä¸ªå®Œæ•´çš„å®éªŒ
3. ä¸æ—§ç‰ˆæœ¬å¯¹æ¯”æ€§èƒ½
4. æ ¹æ®ç»“æœå†³å®šæ˜¯å¦éœ€è¦å¢å¼ºé¢„æµ‹å¤´

---

## ç›¸å…³æ–‡æ¡£

- `BACKEND_REMOVAL_ANALYSIS.md` - åç«¯ç§»é™¤å¯è¡Œæ€§åˆ†æ
- `GRAPH_LEARNER_OPTIMIZATION.md` - å›¾å­¦ä¹ å™¨ä¼˜åŒ–æ–‡æ¡£
- `ADAPTIVE_GRAPH_GUIDE.md` - è‡ªé€‚åº”å›¾å­¦ä¹ æŒ‡å—

---

**æ›´æ–°æ—¶é—´**: 2025å¹´11æœˆ20æ—¥  
**ç‰ˆæœ¬**: v1.0  
**ä½œè€…**: AGPST Team
