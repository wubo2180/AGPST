"""
æµ‹è¯•äº¤æ›¿æ—¶ç©ºæ¶æ„ (Alternating Spatio-Temporal Architecture)

å¿«é€ŸéªŒè¯æ–°æ¶æ„æ˜¯å¦èƒ½æ­£å¸¸è¿è¡Œ
"""

import torch
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from basicts.mask.alternating_st import (
    AlternatingSTModel,
    TemporalEncoder,
    SpatialEncoder,
    FusionLayer,
    STDecoder
)


def test_temporal_encoder():
    """æµ‹è¯•æ—¶é—´ç¼–ç å™¨"""
    print("\n" + "="*60)
    print("æµ‹è¯• TemporalEncoder")
    print("="*60)
    
    B, N, T, D = 4, 358, 12, 96
    
    encoder = TemporalEncoder(
        d_model=D,
        num_heads=4,
        num_layers=2,
        dropout=0.1
    )
    
    x = torch.randn(B, N, T, D)
    out = encoder(x)
    
    print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
    print(f"è¾“å‡ºå½¢çŠ¶: {out.shape}")
    print(f"âœ… TemporalEncoder æµ‹è¯•é€šè¿‡!")
    
    assert out.shape == x.shape, "è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…!"
    return True


def test_spatial_encoder():
    """æµ‹è¯•ç©ºé—´ç¼–ç å™¨"""
    print("\n" + "="*60)
    print("æµ‹è¯• SpatialEncoder")
    print("="*60)
    
    B, N, T, D = 4, 358, 12, 96
    
    encoder = SpatialEncoder(
        num_nodes=N,
        d_model=D,
        num_heads=4,
        num_layers=2,
        dropout=0.1
    )
    
    x = torch.randn(B, N, T, D)
    out = encoder(x)
    
    print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
    print(f"è¾“å‡ºå½¢çŠ¶: {out.shape}")
    print(f"âœ… SpatialEncoder æµ‹è¯•é€šè¿‡!")
    
    assert out.shape == x.shape, "è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…!"
    return True


def test_fusion_layer():
    """æµ‹è¯•èåˆå±‚"""
    print("\n" + "="*60)
    print("æµ‹è¯• FusionLayer")
    print("="*60)
    
    B, N, T, D = 4, 358, 12, 96
    
    for fusion_type in ['concat', 'gated', 'cross_attn']:
        print(f"\næµ‹è¯•èåˆç±»å‹: {fusion_type}")
        
        fusion = FusionLayer(
            d_model=D,
            fusion_type=fusion_type,
            dropout=0.1
        )
        
        temporal_feat = torch.randn(B, N, T, D)
        spatial_feat = torch.randn(B, N, T, D)
        
        fused = fusion(temporal_feat, spatial_feat)
        
        print(f"  æ—¶é—´ç‰¹å¾å½¢çŠ¶: {temporal_feat.shape}")
        print(f"  ç©ºé—´ç‰¹å¾å½¢çŠ¶: {spatial_feat.shape}")
        print(f"  èåˆåå½¢çŠ¶: {fused.shape}")
        
        assert fused.shape == (B, N, T, D), f"{fusion_type} è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…!"
        print(f"  âœ… {fusion_type} èåˆæµ‹è¯•é€šè¿‡!")
    
    return True


def test_st_decoder():
    """æµ‹è¯•æ—¶ç©ºè§£ç å™¨"""
    print("\n" + "="*60)
    print("æµ‹è¯• STDecoder")
    print("="*60)
    
    B, N, T, D = 4, 358, 12, 96
    
    decoder = STDecoder(
        d_model=D,
        num_heads=4,
        dropout=0.1
    )
    
    fused_features = torch.randn(B, N, T, D)
    temporal_comp, spatial_comp = decoder(fused_features)
    
    print(f"è¾“å…¥å½¢çŠ¶: {fused_features.shape}")
    print(f"æ—¶é—´åˆ†é‡å½¢çŠ¶: {temporal_comp.shape}")
    print(f"ç©ºé—´åˆ†é‡å½¢çŠ¶: {spatial_comp.shape}")
    print(f"âœ… STDecoder æµ‹è¯•é€šè¿‡!")
    
    assert temporal_comp.shape == (B, N, T, D), "æ—¶é—´åˆ†é‡å½¢çŠ¶ä¸åŒ¹é…!"
    assert spatial_comp.shape == (B, N, T, D), "ç©ºé—´åˆ†é‡å½¢çŠ¶ä¸åŒ¹é…!"
    return True


def test_full_model():
    """æµ‹è¯•å®Œæ•´æ¨¡å‹"""
    print("\n" + "="*60)
    print("æµ‹è¯• AlternatingSTModel (å®Œæ•´æ¶æ„)")
    print("="*60)
    
    # PEMS03 é…ç½®
    B = 4
    N = 358
    T_in = 12
    T_out = 12
    
    model = AlternatingSTModel(
        num_nodes=N,
        in_steps=T_in,
        out_steps=T_out,
        input_dim=1,
        embed_dim=96,
        num_heads=4,
        temporal_depth_1=2,
        spatial_depth_1=2,
        temporal_depth_2=2,
        spatial_depth_2=2,
        fusion_type='gated',
        dropout=0.05,
        use_denoising=True
    )
    
    # è¾“å…¥æ ¼å¼: (B, T, N, 1) - æ ‡å‡†æ ¼å¼
    x = torch.randn(B, T_in, N, 1)
    
    print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        out = model(x)
    
    print(f"è¾“å‡ºå½¢çŠ¶: {out.shape}")
    print(f"é¢„æœŸè¾“å‡ºå½¢çŠ¶: ({B}, {T_out}, {N}, 1)")
    
    assert out.shape == (B, T_out, N, 1), f"è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…! é¢„æœŸ ({B}, {T_out}, {N}, 1), å®é™… {out.shape}"
    
    # è®¡ç®—å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"\næ¨¡å‹å‚æ•°ç»Ÿè®¡:")
    print(f"  æ€»å‚æ•°é‡: {total_params:,}")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"  å‚æ•°å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB (float32)")
    
    print(f"\nâœ… AlternatingSTModel å®Œæ•´æµ‹è¯•é€šè¿‡!")
    print(f"ğŸ‰ æ­å–œ! æ–°æ¶æ„å¯ä»¥æ­£å¸¸è¿è¡Œ!")
    
    return True


def test_forward_backward():
    """æµ‹è¯•å‰å‘+åå‘ä¼ æ’­"""
    print("\n" + "="*60)
    print("æµ‹è¯•å‰å‘+åå‘ä¼ æ’­ (ç¡®ä¿æ¢¯åº¦æµé€šç•…)")
    print("="*60)
    
    B, N, T_in, T_out = 2, 358, 12, 12
    
    model = AlternatingSTModel(
        num_nodes=N,
        in_steps=T_in,
        out_steps=T_out,
        input_dim=1,
        embed_dim=64,  # å‡å°ç»´åº¦ä»¥åŠ é€Ÿæµ‹è¯•
        num_heads=4,
        temporal_depth_1=1,
        spatial_depth_1=1,
        temporal_depth_2=1,
        spatial_depth_2=1,
        fusion_type='gated',
        dropout=0.1,
        use_denoising=True
    )
    
    x = torch.randn(B, T_in, N, 1)
    target = torch.randn(B, T_out, N, 1)
    
    # å‰å‘ä¼ æ’­
    output = model(x)
    
    # è®¡ç®—æŸå¤±
    loss = torch.nn.functional.mse_loss(output, target)
    
    print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
    print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")
    print(f"æŸå¤±å€¼: {loss.item():.4f}")
    
    # åå‘ä¼ æ’­
    loss.backward()
    
    # æ£€æŸ¥æ¢¯åº¦
    has_grad = False
    for name, param in model.named_parameters():
        if param.grad is not None:
            has_grad = True
            grad_norm = param.grad.norm().item()
            print(f"  {name}: grad_norm = {grad_norm:.6f}")
            if grad_norm == 0:
                print(f"    âš ï¸ è­¦å‘Š: {name} æ¢¯åº¦ä¸º0!")
    
    assert has_grad, "æ²¡æœ‰å‚æ•°æœ‰æ¢¯åº¦!"
    print(f"\nâœ… å‰å‘+åå‘ä¼ æ’­æµ‹è¯•é€šè¿‡!")
    print(f"âœ… æ¢¯åº¦æµæ­£å¸¸!")
    
    return True


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "ğŸš€"*30)
    print("äº¤æ›¿æ—¶ç©ºæ¶æ„ (Alternating ST) å•å…ƒæµ‹è¯•")
    print("ğŸš€"*30)
    
    tests = [
        ("TemporalEncoder", test_temporal_encoder),
        ("SpatialEncoder", test_spatial_encoder),
        ("FusionLayer", test_fusion_layer),
        ("STDecoder", test_st_decoder),
        ("å®Œæ•´æ¨¡å‹", test_full_model),
        ("å‰å‘+åå‘ä¼ æ’­", test_forward_backward),
    ]
    
    passed = 0
    failed = 0
    
    for name, test_func in tests:
        try:
            test_func()
            passed += 1
        except Exception as e:
            failed += 1
            print(f"\nâŒ {name} æµ‹è¯•å¤±è´¥!")
            print(f"é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
    
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)
    print(f"âœ… é€šè¿‡: {passed}/{len(tests)}")
    print(f"âŒ å¤±è´¥: {failed}/{len(tests)}")
    
    if failed == 0:
        print("\nğŸ‰ğŸ‰ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! æ¶æ„å‡†å¤‡å°±ç»ª! ğŸ‰ğŸ‰ğŸ‰")
        print("\nä¸‹ä¸€æ­¥:")
        print("  1. è¿è¡Œè®­ç»ƒ: python main.py --cfg parameters/PEMS03_alternating.yaml")
        print("  2. ç›‘æ§æ€§èƒ½: ç›®æ ‡ MAE < 15")
        print("  3. å¯¹æ¯” baseline: MAE 14.57")
    else:
        print("\nâš ï¸ æœ‰æµ‹è¯•å¤±è´¥,è¯·ä¿®å¤åå†è®­ç»ƒ!")
    
    return failed == 0


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
