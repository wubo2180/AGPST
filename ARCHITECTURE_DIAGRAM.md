# AGPSTæ¨¡å‹æ¶æ„å¯è§†åŒ–

## ğŸ—ï¸ æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         AGPST Model                              â”‚
â”‚                    (basicts/mask/model.py)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  è¾“å…¥æ•°æ®                                   â”‚
        â”‚  â€¢ short_history:  (B, 12, 358, 1)        â”‚
        â”‚  â€¢ long_history:   (B, 864, 358, 1)       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Step 1: Patch Embedding                   â”‚
        â”‚  (basicts/mask/patch_embed.py)            â”‚
        â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”‚
        â”‚  Conv2d(patch_size=12)                     â”‚
        â”‚  (B, 864, 358, 1) â†’ (B, 358, 72, 96)      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Step 2: Positional Encoding               â”‚
        â”‚  (basicts/mask/positional_encoding.py)    â”‚
        â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”‚
        â”‚  Add position info to patches              â”‚
        â”‚  (B, 358, 72, 96) â†’ (B, 358, 72, 96)      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Step 3: Adaptive Graph Learning           â”‚
        â”‚  (basicts/mask/graph_learning.py)         â”‚
        â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
        â”‚  â”‚ AdaptiveGraphLearner         â”‚          â”‚
        â”‚  â”‚  â€¢ Static Graph (358Ã—358)    â”‚          â”‚
        â”‚  â”‚  â€¢ Dynamic Graph (358Ã—358)   â”‚          â”‚
        â”‚  â”‚  â€¢ Multi-scale (Local+Global)â”‚          â”‚
        â”‚  â”‚  â€¢ Top-K Sparsification      â”‚          â”‚
        â”‚  â”‚  â€¢ InfoNCE Contrastive Loss  â”‚          â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
        â”‚  â”‚ DynamicGraphConv             â”‚          â”‚
        â”‚  â”‚  Graph convolution on patchesâ”‚          â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
        â”‚  (B, 358, 72, 96) â†’ (B, 358, 72, 96)      â”‚
        â”‚  + Adjacency Matrix (B, 358, 358)         â”‚
        â”‚  + Contrastive Loss                        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Step 4: Transformer Encoding              â”‚
        â”‚  (basicts/mask/transformer.py)            â”‚
        â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”‚
        â”‚  4-layer Transformer encoder               â”‚
        â”‚  Temporal modeling across patches          â”‚
        â”‚  (B, 358, 72, 96) â†’ (B, 358, 72, 96)      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Step 5: Patch Aggregation                 â”‚
        â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”‚
        â”‚  Mean pooling over patches                 â”‚
        â”‚  (B, 358, 72, 96) â†’ (B, 358, 96)          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Step 6: GraphWaveNet Backend              â”‚
        â”‚  (basicts/graphwavenet)                   â”‚
        â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”‚
        â”‚  Final prediction layer                    â”‚
        â”‚  (B, 358, 96) â†’ (B, 12, 358, 1)           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  è¾“å‡ºé¢„æµ‹                                   â”‚
        â”‚  prediction: (B, 12, 358, 1)              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ æ–‡ä»¶ç»„ç»‡ç»“æ„

```
basicts/mask/
â”‚
â”œâ”€â”€ __init__.py                 # æ¨¡å—å¯¼å‡º
â”‚   â””â”€â”€ exports: AGPSTModel, DynamicGraphConv, etc.
â”‚
â”œâ”€â”€ model.py                    # ğŸ¯ ä¸»æ¨¡å‹
â”‚   â”‚
â”‚   â”œâ”€â”€ class AGPSTModel
â”‚   â”‚   â”œâ”€â”€ __init__()
â”‚   â”‚   â”‚   â”œâ”€â”€ PatchEmbedding
â”‚   â”‚   â”‚   â”œâ”€â”€ PositionalEncoding
â”‚   â”‚   â”‚   â”œâ”€â”€ DynamicGraphConv
â”‚   â”‚   â”‚   â”œâ”€â”€ TransformerLayers
â”‚   â”‚   â”‚   â””â”€â”€ GraphWaveNet
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ forward(history, long_history)
â”‚   â”‚       â”œâ”€â”€ patch_embed()
â”‚   â”‚       â”œâ”€â”€ pos_encode()
â”‚   â”‚       â”œâ”€â”€ graph_conv()
â”‚   â”‚       â”œâ”€â”€ transformer()
â”‚   â”‚       â”œâ”€â”€ aggregate()
â”‚   â”‚       â””â”€â”€ backend()
â”‚   â”‚
â”‚   â””â”€â”€ alias: ForecastingWithAdaptiveGraph = AGPSTModel
â”‚
â”œâ”€â”€ graph_learning.py           # ğŸ“Š å›¾å­¦ä¹ 
â”‚   â”‚
â”‚   â”œâ”€â”€ class AdaptiveGraphLearner
â”‚   â”‚   â”œâ”€â”€ compute_static_graphs()
â”‚   â”‚   â”‚   â”œâ”€â”€ local_graphs (è¿‘é‚»)
â”‚   â”‚   â”‚   â””â”€â”€ global_graphs (é•¿è·ç¦»)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ compute_dynamic_graphs(patches)
â”‚   â”‚   â”‚   â”œâ”€â”€ temporal_attention()
â”‚   â”‚   â”‚   â”œâ”€â”€ dynamic_encoder()
â”‚   â”‚   â”‚   â””â”€â”€ gnn_enhancement()
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ apply_topk_sparsification()
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ compute_contrastive_loss()
â”‚   â”‚   â”‚   â””â”€â”€ InfoNCE loss
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ forward(patches)
â”‚   â”‚       â”œâ”€â”€ static_graphs
â”‚   â”‚       â”œâ”€â”€ dynamic_graphs
â”‚   â”‚       â”œâ”€â”€ fusion
â”‚   â”‚       â””â”€â”€ returns: adj_matrix, loss
â”‚   â”‚
â”‚   â””â”€â”€ class DynamicGraphConv
â”‚       â”œâ”€â”€ graph_learner: AdaptiveGraphLearner
â”‚       â”œâ”€â”€ weight: nn.Parameter
â”‚       â”‚
â”‚       â””â”€â”€ forward(patches)
â”‚           â”œâ”€â”€ learn_graph()
â”‚           â”œâ”€â”€ graph_conv()
â”‚           â””â”€â”€ returns: features, adj, loss
â”‚
â”œâ”€â”€ patch_embed.py              # ğŸ”² PatchåµŒå…¥
â”‚   â”‚
â”‚   â””â”€â”€ class PatchEmbedding
â”‚       â”œâ”€â”€ input_embedding: Conv2d
â”‚       â”œâ”€â”€ _init_weights()
â”‚       â”‚
â”‚       â””â”€â”€ forward(long_history)
â”‚           â”œâ”€â”€ reshape to (B*N, C, L, 1)
â”‚           â”œâ”€â”€ conv2d â†’ (B*N, D, P, 1)
â”‚           â”œâ”€â”€ reshape to (B, N, P, D)
â”‚           â””â”€â”€ returns: patches
â”‚
â”œâ”€â”€ transformer.py              # ğŸ”„ Transformer
â”‚   â”‚
â”‚   â””â”€â”€ class TransformerLayers
â”‚       â”œâ”€â”€ transformer_encoder: TransformerEncoder
â”‚       â”‚   â”œâ”€â”€ num_layers: 4
â”‚       â”‚   â”œâ”€â”€ num_heads: 4
â”‚       â”‚   â””â”€â”€ mlp_ratio: 4
â”‚       â”‚
â”‚       â””â”€â”€ forward(src)
â”‚           â”œâ”€â”€ scale by sqrt(d_model)
â”‚           â”œâ”€â”€ reshape to (P, B*N, D)
â”‚           â”œâ”€â”€ encode
â”‚           â”œâ”€â”€ reshape to (B, N, P, D)
â”‚           â””â”€â”€ returns: encoded
â”‚
â””â”€â”€ positional_encoding.py      # ğŸ“ ä½ç½®ç¼–ç 
    â”‚
    â””â”€â”€ class PositionalEncoding
        â”œâ”€â”€ learnable position embeddings
        â”‚
        â””â”€â”€ forward(x)
            â””â”€â”€ returns: x + pos_embed
```

---

## ğŸ”„ æ•°æ®æµè½¬æ¢

```
è¾“å…¥é˜¶æ®µ:
â”€â”€â”€â”€â”€â”€â”€â”€â”€
short_history:     [B, 12, 358, 1]    â”
long_history:      [B, 864, 358, 1]   â”˜ â†’ ä»…ä½¿ç”¨long_history

æ ¼å¼è½¬æ¢:
â”€â”€â”€â”€â”€â”€â”€â”€â”€
(B, 864, 358, 1) â†’ transpose â†’ (B, 358, 864, 1)

Patch Embedding:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
(B, 358, 864, 1) 
    â†’ unsqueeze â†’ (B, 358, 864, 1, 1)
    â†’ reshape â†’ (B*358, 1, 864, 1)
    â†’ Conv2d(kernel=12, stride=12) â†’ (B*358, 96, 72, 1)
    â†’ squeeze & reshape â†’ (B, 358, 72, 96)
    â†’ transpose â†’ (B, 358, 72, 96)
                  â”œâ”€ B: batch_size (16)
                  â”œâ”€ N: num_nodes (358)
                  â”œâ”€ P: num_patches (72 = 864/12)
                  â””â”€ D: embed_dim (96)

Positional Encoding:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
(B, 358, 72, 96) + pos_embed â†’ (B, 358, 72, 96)

Graph Learning:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
(B, 358, 72, 96) â†’ AdaptiveGraphLearner â†’ (B, 358, 358) adjacency
                                         + contrastive_loss

Graph Convolution:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
For each patch p in [0, 72):
    (B, 358, 96) @ weight â†’ (B, 358, 96)
    (B, 358, 358) @ (B, 358, 96) â†’ (B, 358, 96)
Stack â†’ (B, 358, 72, 96)

Transformer:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
(B, 358, 72, 96)
    â†’ reshape â†’ (B*358, 72, 96)
    â†’ transpose â†’ (72, B*358, 96)  # (seq_len, batch, dim)
    â†’ TransformerEncoder(4 layers) â†’ (72, B*358, 96)
    â†’ transpose â†’ (B*358, 72, 96)
    â†’ reshape â†’ (B, 358, 72, 96)

Aggregation:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
(B, 358, 72, 96) â†’ mean(dim=2) â†’ (B, 358, 96)

Backend:
â”€â”€â”€â”€â”€â”€â”€â”€
(B, 358, 96) 
    â†’ permute â†’ (B, 96, 358, 1)
    â†’ GraphWaveNet â†’ (B, 358, 12, 1)
    â†’ permute â†’ (B, 12, 358, 1)

è¾“å‡º:
â”€â”€â”€â”€â”€
prediction: [B, 12, 358, 1]
```

---

## ğŸ“Š å‚æ•°ç»Ÿè®¡

### æ¨¡å‹ç»„ä»¶å‚æ•°é‡
```
1. PatchEmbedding
   â””â”€â”€ Conv2d(1, 96, kernel=(12,1))
       Parameters: 1 Ã— 96 Ã— 12 Ã— 1 = 1,152

2. PositionalEncoding
   â””â”€â”€ Learnable embeddings
       Parameters: ~7,000

3. AdaptiveGraphLearner
   â”œâ”€â”€ Static embeddings: 358Ã—10Ã—4Ã—2 = ~28,640
   â”œâ”€â”€ Local embeddings: 358Ã—5Ã—2Ã—2 = ~7,160
   â”œâ”€â”€ Global embeddings: 358Ã—10Ã—2Ã—2 = ~14,320
   â”œâ”€â”€ Temporal attention: ~40,000
   â”œâ”€â”€ Dynamic encoder: ~20,000
   â””â”€â”€ Fusion networks: ~10,000
       Subtotal: ~120,000

4. DynamicGraphConv
   â””â”€â”€ Weight matrix: 96Ã—96 = 9,216

5. TransformerLayers (4 layers)
   â””â”€â”€ Each layer: ~150,000
       Subtotal: ~600,000

6. GraphWaveNet
   â””â”€â”€ Backend prediction: ~500,000

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: ~1,270,000 parameters
```

---

## ğŸ¯ å…³é”®ç‰¹æ€§

### 1. Multi-scale Graph Learning
```
Local Graph (2 heads)
  â”œâ”€â”€ Small receptive field
  â”œâ”€â”€ Captures nearby relationships
  â””â”€â”€ Higher temperature (2Ã—)

Global Graph (2 heads)
  â”œâ”€â”€ Large receptive field
  â”œâ”€â”€ Captures long-range dependencies
  â””â”€â”€ Lower temperature (0.5Ã—)

Fusion
  â””â”€â”€ Adaptive attention-based weighting
```

### 2. Dynamic + Static Fusion
```
Static Graph
  â”œâ”€â”€ Pre-learned node embeddings
  â”œâ”€â”€ Captures fixed topology
  â””â”€â”€ Shape: (H, N, N)

Dynamic Graph
  â”œâ”€â”€ Computed from current batch
  â”œâ”€â”€ Adapts to input patterns
  â””â”€â”€ Shape: (B, H, N, N)

Fusion Weight
  â”œâ”€â”€ Learned from features
  â””â”€â”€ Î±Ã—static + (1-Î±)Ã—dynamic
```

### 3. Contrastive Learning
```
InfoNCE Loss
  â”œâ”€â”€ Positive pairs: same node, different time
  â”œâ”€â”€ Negative pairs: different nodes
  â”œâ”€â”€ Temperature: 0.2
  â””â”€â”€ Improves graph representation quality
```

---

## ğŸ”§ é…ç½®å‚æ•°æ˜ å°„

```yaml
PEMS03_direct_forecasting.yaml
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
num_nodes: 358          â†’ AGPSTModel(num_nodes=358)
dim: 10                 â†’ AdaptiveGraphLearner(node_dim=10)
topK: 10                â†’ AdaptiveGraphLearner(topk=10)
patch_size: 12          â†’ PatchEmbedding(patch_size=12)
in_channel: 1           â†’ PatchEmbedding(in_channel=1)
embed_dim: 96           â†’ PatchEmbedding(embed_dim=96)
num_heads: 4            â†’ TransformerLayers(num_heads=4)
graph_heads: 4          â†’ AdaptiveGraphLearner(graph_heads=4)
mlp_ratio: 4            â†’ TransformerLayers(mlp_ratio=4)
dropout: 0.1            â†’ All modules
encoder_depth: 4        â†’ TransformerLayers(nlayers=4)
contrastive_weight: 0.05 â†’ Loss weighting
```

---

**Version**: 2.0  
**Last Updated**: 2025-01-11
