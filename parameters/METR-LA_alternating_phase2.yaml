# ============================================================================
# Alternating Spatio-Temporal Architecture - Phase 2 Optimized
# Dataset: METR-LA (207 nodes)
# Model: AlternatingSTModel_Phase2
# Optimizations: Skip Connections + Parameter Sharing + Batch Processing
# Learning Rate: 0.0005 (based on diagnostic results)
# ============================================================================

# --------------------- Basic Information ---------------------
description: 'Phase 2 Optimized Alternating ST Model with Skip Connections'
model_name: 'AlternatingSTModel_Phase2'
dataset_name: "METR-LA"
dataset_type: "Traffic speed"
mode: train

# --------------------- Device Configuration ---------------------
device: 'cuda'
gpu_num: 1

# --------------------- Dataset Configuration ---------------------
dataset_dir: 'datasets/'
adj_dir: 'datasets/METR-LA/adj_mx.pkl'
input_len: 12
output_len: 12
num_nodes: 207  # METR-LA has 207 nodes
use_timestamps: False
norm_each_channel: True
rescale: False
memmap: False
local: True

# --------------------- Training Configuration ---------------------
epochs: 150
batch_size: 32
lr: 0.0005  # Optimized based on diagnostic: MAE=4.5387
weight_decay: 0.0001
eps: 0.001
evaluation_horizons: 12

# Gradient clipping
train:
    clip_grad_param:
        max_norm: 5.0
    null_val: 0.0

# --------------------- Phase 2 Architecture Configuration ---------------------
# Feature configuration
in_channel: 1
froward_features: [0]
target_features: [0]

# Core architecture parameters
embed_dim: 96  # Feature dimension
dropout: 0.1
num_heads: 4
mlp_ratio: 4

# Temporal and Spatial depth (simplified in Phase 2)
temporal_depth: 2  # Shared temporal encoder depth
spatial_depth: 2   # Shared spatial encoder depth

# Fusion mechanism
fusion_type: 'gated'  # Options: 'gated', 'concat', 'cross_attn'

# Advanced features
use_positional_encoding: True
use_layer_norm: True

# --------------------- Phase 2 Optimizations ---------------------
# Skip Connections: Multi-level residual connections
use_skip_connections: True
skip_connection_type: 'add'  # Options: 'add', 'concat'
                             # 'add': Gated residual (memory efficient, stable gradients)
                             # 'concat': Feature concatenation (more expressive but larger)

# Parameter Sharing: Share encoders between Stage 1 and Stage 2
use_parameter_sharing: True  # Reduces ~40% parameters, improves generalization

# Batch Processing: Vectorized spatial encoding
batch_spatial_encoding: True  # ~30% speedup by avoiding loops

# --------------------- Denoise Settings ---------------------
use_denoising: False  # Disabled in Phase 2 for speed

# --------------------- Adaptive Graph Learning ---------------------
use_advanced_graph: True
graph_heads: 4
dim: 10  # Node embedding dimension
topK: 10  # Top-K sparsification

# --------------------- Evaluation Metrics ---------------------
metrics:
    MAE: "masked_mae"
    RMSE: "masked_rmse"
    MAPE: "masked_mape"

# --------------------- Optimization ---------------------
# Mixed precision training (enabled for Phase 2)
use_amp: False  # Automatic mixed precision for faster training

# --------------------- Model Saving ---------------------
save_model: True
model_save_path: 'checkpoints/METR-LA_AlternatingST_Phase2/'

# --------------------- Logging Configuration ---------------------
test_mode: False
swanlab_mode: 'online'
log_dir: 'logs/METR-LA_AlternatingST_Phase2/'

# --------------------- Phase 2 Architecture Summary ---------------------
# Optimizations over Phase 1:
# 1. Skip Connections: Multi-level residual learning
#    - Input → Stage 2 (skip_input)
#    - Stage 1 Fusion → Stage 2 Fusion (skip_fused_1)
#    - Decoder → Stage 2 (skip connection with gating)
#
# 2. Parameter Sharing: 
#    - Stage 1 and Stage 2 share the same encoders
#    - Reduces parameters from ~1.23M to ~0.74M (~40% reduction)
#
# 3. Batch Processing:
#    - Vectorized spatial encoding: (B, N, T, D) → (B*T, N, D)
#    - Eliminates time-step loop, ~30% speedup
#
# Expected Benefits:
#   - Better gradient flow (skip connections)
#   - Improved generalization (parameter sharing)
#   - Faster training (batch processing + AMP)
#   - Target MAE < 4.0 (vs Phase 1 MAE ~4.5)
# ============================================================================

