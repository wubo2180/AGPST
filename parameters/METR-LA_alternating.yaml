# ============================================================================
# Alternating Spatio-Temporal Architecture Configuration
# Dataset: METR-LA (207 nodes)
# Model: AlternatingSTModel
# Architecture: Temporal Encoder â†’ Spatial Encoder â†’ Fusion â†’ ST Decoder (Ã—2 stages)
# ============================================================================

# --------------------- Basic Information ---------------------
description: 'Alternating Spatio-Temporal Model for Traffic Forecasting'
model_name: 'AlternatingSTModel'
dataset_name: "METR-LA"
dataset_type: "Traffic speed"
mode: train

# --------------------- Device Configuration ---------------------
device: 'cuda'
gpu_num: 1

# --------------------- Dataset Configuration ---------------------
dataset_dir: 'datasets/'
adj_dir: 'datasets/METR-LA/adj_mx.pkl'
input_len: 12
output_len: 12
num_nodes: 207  # METR-LA has 207 nodes
use_timestamps: False
norm_each_channel: True
rescale: False
memmap: False
local: True

# --------------------- Training Configuration ---------------------
epochs: 100
batch_size: 32
lr: 0.001  # Initial learning rate
weight_decay: 0.0005  # L2 regularization (prevent overfitting)
eps: 0.001
evaluation_horizons: 12

# ðŸ”¥ Learning Rate Scheduler - Optimized ReduceLROnPlateau
# Improvements over original configuration:
#   1. patience: 5 â†’ 10 (more conservative, avoids premature decay)
#   2. factor: 0.5 â†’ 0.5 (keep, can use 0.7 for gentler decay)
#   3. Added min_lr: 0.000001 (prevents learning rate from dropping to 0)
lr_patience: 10        # Decay LR if val loss doesn't improve for 10 epochs (was 5)
lr_decay_factor: 0.5   # Decay by factor of 0.5 each time (can use 0.7 for gentler)
min_lr: 0.000001       # Minimum learning rate protection (1e-6), prevents dropping to 0
# 
# How it works:
#   - Monitors validation loss (val_loss)
#   - If val loss doesn't decrease for 10 consecutive epochs
#   - Learning rate = learning rate Ã— 0.5
#   - But will not go below min_lr = 0.000001
# 
# Expected LR schedule (compared to original):
#   Original: lr â†’ near 0 around epoch 20 (too early)
#   New: First decay around epoch 30-40 (more reasonable)
#        Subsequent adaptive adjustments based on val loss

# Gradient clipping
train:
    clip_grad_param:
        max_norm: 5.0
    null_val: 0.0

# --------------------- Alternating ST Architecture ---------------------
# Feature configuration
in_channel: 1

# Core architecture parameters
embed_dim: 64  # Feature dimension
dropout: 0.1
num_heads: 4
mlp_ratio: 4
pe_type: 'adaptive'  # Options: 'cyclic', 'adaptive'
# Stage 1: First temporal-spatial encoding
temporal_depth_1: 2  # Depth of first temporal encoder
spatial_depth_1: 2   # Depth of first spatial encoder

# Decoder: Decodes fused features back to temporal/spatial components
decoder_depth: 2
num_decoder_queries: 24  # 12 (temporal) + 12 (spatial)

# Stage 2: Second temporal-spatial encoding
temporal_depth_2: 2  # Depth of second temporal encoder
spatial_depth_2: 2   # Depth of second spatial encoder

# Fusion mechanism
fusion_type: 'cross_attn'  # Options: 'gated', 'concat', 'cross_attn'
# 'gated': Learnable gates Î±Â·temporal + (1-Î±)Â·spatial (default, more stable)
# 'concat': Simple concatenation + projection (faster but less expressive)
# 'cross_attn': Cross-attention between temporal and spatial (most powerful but slower)

# Advanced features
use_positional_encoding: True  # Add positional encoding
use_layer_norm: True  # Use layer normalization
# --------------------- Denoise Settings ---------------------
use_denoising: True  # Enable denoising for input data
denoise_type: 'conv'  # Options: 'conv', 'attention'
                       # 'conv': 1D convolutional denoiser (fast)
                       # 'attention': Attention-based denoiser (slower but effective)
                       # 'conv' is recommended for speed and effectiveness.
                       # 'attention' can be used for more complex scenarios.

# --------------------- Adaptive Graph Learning ---------------------
# These parameters are used for spatial encoding
use_advanced_graph: True
graph_heads: 4
dim: 10  # Node embedding dimension
topK: 10  # Top-K sparsification for graph


# --------------------- Evaluation Metrics ---------------------
metrics:
    MAE: "masked_mae"
    RMSE: "masked_rmse"
    MAPE: "masked_mape"

# --------------------- Optimization ---------------------
# Mixed precision training (optional, can speed up training by 30-50%)
use_amp: False  # Set to True to enable automatic mixed precision

# --------------------- Model Saving ---------------------
save_model: True
model_save_path: 'checkpoints/METR-LA_AlternatingST/'

# --------------------- Logging Configuration ---------------------
test_mode: False
swanlab_mode: 'online'
log_dir: 'logs/METR-LA_AlternatingST/'

# --------------------- Architecture Summary ---------------------
# Input: (B, N=207, T=12, D=1)
# 
# Stage 1:
#   TemporalEncoder1: (B, N, T, D) â†’ (B, N, T, embed_dim=64)
#   SpatialEncoder1:  (B, N, T, D) â†’ (B, N, T, embed_dim=64)
#   FusionLayer1:     Fuses temporal & spatial features
#
# STDecoder:
#   Decodes fused features to temporal and spatial components
#   Temporal queries: (B, N, T, embed_dim)
#   Spatial queries:  (B, N, T, embed_dim)
#
# Stage 2:
#   TemporalEncoder2: Processes temporal queries
#   SpatialEncoder2:  Processes spatial queries
#   FusionLayer2:     Final fusion
#
# Output Head: Projects to (B, N, output_len=12, out_dim=1)
#
# Total Parameters: ~1.23M (4.68 MB)
# ============================================================================
