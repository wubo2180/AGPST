# ============================================================================
# Alternating Spatio-Temporal Architecture Configuration
# Dataset: METR-LA (207 nodes)
# Model: AlternatingSTModel
# Architecture: Temporal Encoder → Spatial Encoder → Fusion → ST Decoder (×2 stages)
# ============================================================================

# --------------------- Basic Information ---------------------
description: 'Alternating Spatio-Temporal Model for Traffic Forecasting'
model_name: 'AlternatingSTModel'
dataset_name: "METR-LA"
dataset_type: "Traffic speed"
mode: train

# --------------------- Device Configuration ---------------------
device: 'cuda'
gpu_num: 1

# --------------------- Dataset Configuration ---------------------
dataset_dir: 'datasets/'
adj_dir: 'datasets/METR-LA/adj_mx.pkl'
input_len: 12
output_len: 12
num_nodes: 207  # METR-LA has 207 nodes
use_timestamps: False
norm_each_channel: True
rescale: False
memmap: False
local: True

# --------------------- Training Configuration ---------------------
epochs: 100
batch_size: 32
lr: 0.0005
weight_decay: 0.0001
eps: 0.001
evaluation_horizons: 12

# Gradient clipping
train:
    clip_grad_param:
        max_norm: 5.0
    null_val: 0.0

# --------------------- Alternating ST Architecture ---------------------
# Feature configuration
in_channel: 1
froward_features: [0]
target_features: [0]

# Core architecture parameters
embed_dim: 96  # Feature dimension
dropout: 0.1
num_heads: 4
mlp_ratio: 4

# Stage 1: First temporal-spatial encoding
temporal_depth_1: 2  # Depth of first temporal encoder
spatial_depth_1: 2   # Depth of first spatial encoder

# Decoder: Decodes fused features back to temporal/spatial components
decoder_depth: 2
num_decoder_queries: 24  # 12 (temporal) + 12 (spatial)

# Stage 2: Second temporal-spatial encoding
temporal_depth_2: 2  # Depth of second temporal encoder
spatial_depth_2: 2   # Depth of second spatial encoder

# Fusion mechanism
fusion_type: 'gated'  # Options: 'gated', 'concat', 'cross_attn'
# 'gated': Learnable gates α·temporal + (1-α)·spatial (default, more stable)
# 'concat': Simple concatenation + projection (faster but less expressive)
# 'cross_attn': Cross-attention between temporal and spatial (most powerful but slower)

# Advanced features
use_positional_encoding: True  # Add positional encoding
use_layer_norm: True  # Use layer normalization
# --------------------- Denoise Settings ---------------------
use_denoising: False  # Enable denoising for input data
denoise_type: 'conv'  # Options: 'conv', 'attention'
                       # 'conv': 1D convolutional denoiser (fast)
                       # 'attention': Attention-based denoiser (slower but effective)
                       # 'conv' is recommended for speed and effectiveness.
                       # 'attention' can be used for more complex scenarios.

# --------------------- Adaptive Graph Learning ---------------------
# These parameters are used for spatial encoding
use_advanced_graph: True
graph_heads: 4
dim: 10  # Node embedding dimension
topK: 10  # Top-K sparsification for graph


# --------------------- Evaluation Metrics ---------------------
metrics:
    MAE: "masked_mae"
    RMSE: "masked_rmse"
    MAPE: "masked_mape"

# --------------------- Optimization ---------------------
# Mixed precision training (optional, can speed up training by 30-50%)
use_amp: False  # Set to True to enable automatic mixed precision

# --------------------- Model Saving ---------------------
save_model: True
model_save_path: 'checkpoints/METR-LA_AlternatingST/'

# --------------------- Logging Configuration ---------------------
test_mode: False
swanlab_mode: 'online'
log_dir: 'logs/METR-LA_AlternatingST/'

# --------------------- Architecture Summary ---------------------
# Input: (B, N=207, T=12, D=1)
# 
# Stage 1:
#   TemporalEncoder1: (B, N, T, D) → (B, N, T, embed_dim=96)
#   SpatialEncoder1:  (B, N, T, D) → (B, N, T, embed_dim=96)
#   FusionLayer1:     Fuses temporal & spatial features
#
# STDecoder:
#   Decodes fused features to temporal and spatial components
#   Temporal queries: (B, N, T, embed_dim)
#   Spatial queries:  (B, N, T, embed_dim)
#
# Stage 2:
#   TemporalEncoder2: Processes temporal queries
#   SpatialEncoder2:  Processes spatial queries
#   FusionLayer2:     Final fusion
#
# Output Head: Projects to (B, N, output_len=12, out_dim=1)
#
# Total Parameters: ~1.23M (4.68 MB)
# ============================================================================
