# ============================================================================
# Alternating Spatio-Temporal Architecture Configuration
# Dataset: METR-LA (207 nodes)
# Model: AlternatingSTModel
# Architecture: Temporal Encoder â†’ Spatial Encoder â†’ Fusion â†’ ST Decoder (Ã—2 stages)
# ============================================================================

# --------------------- Basic Information ---------------------
description: 'Alternating Spatio-Temporal Model for Traffic Forecasting'
model_name: 'AlternatingSTModel'
dataset_name: "METR-LA"
dataset_type: "Traffic speed"
mode: train

# --------------------- Device Configuration ---------------------
device: 'cuda'
gpu_num: 1

# --------------------- Dataset Configuration ---------------------
dataset_dir: 'datasets/'
adj_dir: 'datasets/METR-LA/adj_mx.pkl'
input_len: 12
output_len: 12
num_nodes: 207  # METR-LA has 207 nodes
use_timestamps: False
norm_each_channel: True
rescale: False
memmap: False
local: True

# --------------------- Training Configuration ---------------------
epochs: 100
batch_size: 32
lr: 0.001  # åˆå§‹å­¦ä¹ ç‡
weight_decay: 0.0005  # L2 æ­£åˆ™åŒ– (é˜²æ­¢è¿‡æ‹Ÿåˆ)
eps: 0.001
evaluation_horizons: 12

# ğŸ”¥ Learning Rate Scheduler - ä¼˜åŒ–ç‰ˆ ReduceLROnPlateau
# ç›¸æ¯”åŸé…ç½®çš„æ”¹è¿›:
#   1. patience: 5 â†’ 10 (æ›´ä¿å®ˆ,ä¸ä¼šè¿‡æ—©è¡°å‡)
#   2. factor: 0.5 â†’ 0.5 (ä¿æŒ,ä¹Ÿå¯æ”¹ä¸º 0.7 æ›´æ¸©å’Œ)
#   3. æ·»åŠ  min_lr: 1e-6 (é˜²æ­¢å­¦ä¹ ç‡é™ä¸º 0)
lr_patience: 10        # éªŒè¯æŸå¤± 10 ä¸ª epoch ä¸æ”¹è¿›æ‰è¡°å‡ (åŸæ¥æ˜¯ 5)
lr_decay_factor: 0.5   # æ¯æ¬¡è¡°å‡ä¸ºåŸæ¥çš„ 0.5 å€ (å¯æ”¹ä¸º 0.7 æ›´æ¸©å’Œ)
min_lr: 1e-6          # æœ€å°å­¦ä¹ ç‡ä¿æŠ¤,é˜²æ­¢é™åˆ° 0
# 
# å·¥ä½œåŸç†:
#   - ç›‘æ§éªŒè¯æŸå¤± (val_loss)
#   - å¦‚æœè¿ç»­ 10 ä¸ª epoch éªŒè¯æŸå¤±ä¸ä¸‹é™
#   - å­¦ä¹ ç‡ = å­¦ä¹ ç‡ Ã— 0.5
#   - ä½†ä¸ä¼šä½äº min_lr = 1e-6
# 
# é¢„æœŸå­¦ä¹ ç‡å˜åŒ– (ç›¸æ¯”åŸé…ç½®):
#   åŸé…ç½®: ~20 epoch æ—¶ lr â†’ æ¥è¿‘ 0 (è¿‡æ—©)
#   æ–°é…ç½®: ~30-40 epoch é¦–æ¬¡è¡°å‡ (æ›´åˆç†)
#            åç»­æ ¹æ®éªŒè¯æŸå¤±è‡ªé€‚åº”è°ƒæ•´

# Gradient clipping
train:
    clip_grad_param:
        max_norm: 5.0
    null_val: 0.0

# --------------------- Alternating ST Architecture ---------------------
# Feature configuration
in_channel: 1
froward_features: [0]
target_features: [0]

# Core architecture parameters
embed_dim: 64  # Feature dimension
dropout: 0.1
num_heads: 4
mlp_ratio: 4

# Stage 1: First temporal-spatial encoding
temporal_depth_1: 2  # Depth of first temporal encoder
spatial_depth_1: 2   # Depth of first spatial encoder

# Decoder: Decodes fused features back to temporal/spatial components
decoder_depth: 2
num_decoder_queries: 24  # 12 (temporal) + 12 (spatial)

# Stage 2: Second temporal-spatial encoding
temporal_depth_2: 2  # Depth of second temporal encoder
spatial_depth_2: 2   # Depth of second spatial encoder

# Fusion mechanism
fusion_type: 'cross_attn'  # Options: 'gated', 'concat', 'cross_attn'
# 'gated': Learnable gates Î±Â·temporal + (1-Î±)Â·spatial (default, more stable)
# 'concat': Simple concatenation + projection (faster but less expressive)
# 'cross_attn': Cross-attention between temporal and spatial (most powerful but slower)

# Advanced features
use_positional_encoding: True  # Add positional encoding
use_layer_norm: True  # Use layer normalization
# --------------------- Denoise Settings ---------------------
use_denoising: True  # Enable denoising for input data
denoise_type: 'conv'  # Options: 'conv', 'attention'
                       # 'conv': 1D convolutional denoiser (fast)
                       # 'attention': Attention-based denoiser (slower but effective)
                       # 'conv' is recommended for speed and effectiveness.
                       # 'attention' can be used for more complex scenarios.

# --------------------- Adaptive Graph Learning ---------------------
# These parameters are used for spatial encoding
use_advanced_graph: True
graph_heads: 4
dim: 10  # Node embedding dimension
topK: 10  # Top-K sparsification for graph


# --------------------- Evaluation Metrics ---------------------
metrics:
    MAE: "masked_mae"
    RMSE: "masked_rmse"
    MAPE: "masked_mape"

# --------------------- Optimization ---------------------
# Mixed precision training (optional, can speed up training by 30-50%)
use_amp: False  # Set to True to enable automatic mixed precision

# --------------------- Model Saving ---------------------
save_model: True
model_save_path: 'checkpoints/METR-LA_AlternatingST/'

# --------------------- Logging Configuration ---------------------
test_mode: False
swanlab_mode: 'online'
log_dir: 'logs/METR-LA_AlternatingST/'

# --------------------- Architecture Summary ---------------------
# Input: (B, N=207, T=12, D=1)
# 
# Stage 1:
#   TemporalEncoder1: (B, N, T, D) â†’ (B, N, T, embed_dim=64)
#   SpatialEncoder1:  (B, N, T, D) â†’ (B, N, T, embed_dim=64)
#   FusionLayer1:     Fuses temporal & spatial features
#
# STDecoder:
#   Decodes fused features to temporal and spatial components
#   Temporal queries: (B, N, T, embed_dim)
#   Spatial queries:  (B, N, T, embed_dim)
#
# Stage 2:
#   TemporalEncoder2: Processes temporal queries
#   SpatialEncoder2:  Processes spatial queries
#   FusionLayer2:     Final fusion
#
# Output Head: Projects to (B, N, output_len=12, out_dim=1)
#
# Total Parameters: ~1.23M (4.68 MB)
# ============================================================================
