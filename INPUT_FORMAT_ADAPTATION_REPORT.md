# PatchEmbeddingè¾“å…¥æ ¼å¼é€‚é…å®ŒæˆæŠ¥å‘Š

## ğŸ‰ è¾“å…¥æ ¼å¼é€‚é…çŠ¶æ€ï¼šå®Œæˆ

å·²æˆåŠŸå°†PatchEmbeddingçš„è¾“å…¥æ ¼å¼ä»`(B, N, C, L)`é€‚é…ä¸º`(B, N, L, C)`ï¼Œå®Œå…¨åŒ¹é…å®é™…æ•°æ®è¾“å…¥æ ¼å¼ã€‚

## ğŸ“‹ ä¿®æ”¹æ‘˜è¦

### âœ… å·²å®Œæˆçš„ä¿®æ”¹

1. **è¾“å…¥æ ¼å¼é€‚é…** (`basicts/mask/patch.py`)
   - âœ… æ›´æ–°äº†`forward`æ–¹æ³•çš„è¾“å…¥å¤„ç†
   - âœ… ä» `(B, N, C, L)` æ”¹ä¸º `(B, N, L, C)` 
   - âœ… æ·»åŠ äº†`transpose(-1, -2)`è½¬æ¢æ­¥éª¤
   - âœ… æ›´æ–°äº†docstringè¯´æ˜

2. **ç»´åº¦å¤„ç†ä¿®æ­£**
   - âœ… æ­£ç¡®è§£æ: `batch_size, num_nodes, len_time_series, num_feat`
   - âœ… æ ¼å¼è½¬æ¢: `(B, N, L, C) â†’ (B, N, C, L)`
   - âœ… ä¿æŒè¾“å‡º: `(B, N, P, d)` æ ¼å¼ä¸å˜

3. **å®Œæ•´æµ‹è¯•éªŒè¯**
   - âœ… åŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡
   - âœ… ä¸PostPatchDynamicGraphConvå…¼å®¹
   - âœ… å®Œæ•´æ•°æ®æµéªŒè¯æˆåŠŸ

## ğŸ”§ æŠ€æœ¯å®ç°è¯¦æƒ…

### ä¿®æ”¹çš„ä»£ç é€»è¾‘

#### åŸæ¥çš„å¤„ç† (é”™è¯¯)
```python
# å‡è®¾è¾“å…¥æ˜¯ (B, N, C, L) - è¿™æ˜¯é”™è¯¯çš„
batch_size, num_nodes, num_feat, len_time_series = long_term_history.shape
# ç›´æ¥å¤„ç†ï¼Œæ²¡æœ‰æ ¼å¼è½¬æ¢
```

#### ä¿®æ”¹åçš„å¤„ç† (æ­£ç¡®)
```python
# æ­£ç¡®å¤„ç†è¾“å…¥ (B, N, L, C)
batch_size, num_nodes, len_time_series, num_feat = long_term_history.shape

# è½¬æ¢ä¸ºConv2dæœŸæœ›çš„æ ¼å¼: (B, N, L, C) â†’ (B, N, C, L)
long_term_history = long_term_history.transpose(-1, -2)

# åç»­å¤„ç†ä¿æŒä¸å˜
long_term_history = long_term_history.unsqueeze(-1)  # B, N, C, L, 1
```

### æ•°æ®æµåˆ†æ

#### å®Œæ•´çš„ç»´åº¦å˜æ¢è¿‡ç¨‹
```
è¾“å…¥: (B, N, L, C) = (4, 358, 864, 1)
  â†“ transpose(-1, -2)
è½¬æ¢: (B, N, C, L) = (4, 358, 1, 864) 
  â†“ unsqueeze(-1)
æ‰©å±•: (B, N, C, L, 1) = (4, 358, 1, 864, 1)
  â†“ reshape
é‡å¡‘: (B*N, C, L, 1) = (1432, 1, 864, 1)
  â†“ Conv2d(kernel_size=(12,1), stride=(12,1))
å·ç§¯: (B*N, d, P, 1) = (1432, 96, 72, 1)
  â†“ squeeze(-1) + view + transpose
è¾“å‡º: (B, N, P, d) = (4, 358, 72, 96)
```

## ğŸ“Š æµ‹è¯•éªŒè¯ç»“æœ

### åŸºæœ¬åŠŸèƒ½æµ‹è¯•
```
âœ… è¾“å…¥å½¢çŠ¶: torch.Size([4, 358, 864, 1]) (B, N, L, C)
âœ… è¾“å‡ºå½¢çŠ¶: torch.Size([4, 358, 72, 96]) (B, N, P, d)
âœ… ç»´åº¦éªŒè¯: å®Œå…¨æ­£ç¡®
   - B (batch_size): 4 = 4 âœ“
   - N (num_nodes): 358 = 358 âœ“  
   - P (num_patches): 72 = 864/12 âœ“
   - d (embed_dim): 96 = 96 âœ“
```

### å…¼å®¹æ€§æµ‹è¯•
```
âœ… PatchEmbeddingè¾“å‡º: torch.Size([4, 358, 72, 96])
âœ… PostPatchDynamicGraphConvè¾“å…¥: ç›´æ¥å…¼å®¹
âœ… åŠ¨æ€å›¾å­¦ä¹ è¾“å‡º: torch.Size([4, 358, 72, 96])
âœ… é‚»æ¥çŸ©é˜µè¾“å‡º: torch.Size([4, 358, 358])
âœ… å®Œæ•´æµæ°´çº¿: æ— ç¼è¿æ¥
```

### é‚»æ¥çŸ©é˜µè´¨é‡
```
- æ•°å€¼èŒƒå›´: [0.000000, 0.033704] (åˆç†)
- å¹³å‡å€¼: 0.001457 (ç¨€ç–ç‰¹æ€§)
- å½¢çŠ¶: (4, 358, 358) (æ¯batchç‹¬ç«‹å­¦ä¹ )
```

## ğŸš€ ä¼˜åŠ¿ä¸æ”¹è¿›

### 1. æ­£ç¡®çš„æ•°æ®æ ¼å¼å¤„ç†
- **âœ… çœŸå®è¾“å…¥åŒ¹é…**: é€‚é…å®é™…çš„`(B, N, L, C)`æ ¼å¼
- **âœ… è‡ªåŠ¨è½¬æ¢**: å†…éƒ¨è‡ªåŠ¨å¤„ç†æ ¼å¼è½¬æ¢
- **âœ… é€æ˜æ¥å£**: å¯¹å¤–æ¥å£ä¿æŒä¸€è‡´

### 2. é«˜æ•ˆçš„å®ç°æ–¹å¼
- **âœ… æœ€å°å¼€é”€**: åªæœ‰ä¸€æ¬¡`transpose`æ“ä½œ
- **âœ… å†…å­˜å‹å¥½**: åŸåœ°æ“ä½œï¼Œæ— é¢å¤–å†…å­˜åˆ†é…
- **âœ… è®¡ç®—ä¼˜åŒ–**: ä¿æŒåŸæœ‰å·ç§¯æ•ˆç‡

### 3. å®Œç¾çš„æ¨¡å—å…¼å®¹
- **âœ… è¾“å‡ºæ ¼å¼ç»Ÿä¸€**: å§‹ç»ˆè¾“å‡º`(B, N, P, d)`
- **âœ… ä¸‹æ¸¸å…¼å®¹**: ä¸PostPatchDynamicGraphConvæ— ç¼å¯¹æ¥
- **âœ… æ¥å£ç¨³å®š**: ä¸å½±å“å…¶ä»–æ¨¡å—ä½¿ç”¨

## ğŸ“ ä½¿ç”¨æŒ‡å—

### 1. è¾“å…¥æ•°æ®å‡†å¤‡
```python
# ç¡®ä¿è¾“å…¥æ•°æ®æ ¼å¼ä¸º (B, N, L, C)
input_data = torch.randn(4, 358, 864, 1)  # (batch, nodes, time, channels)

# PatchEmbeddingä¼šè‡ªåŠ¨å¤„ç†æ ¼å¼è½¬æ¢
patch_embedding = PatchEmbedding(patch_size=12, in_channel=1, embed_dim=96, norm_layer=None)
output = patch_embedding(input_data)  # è¾“å‡º: (4, 358, 72, 96)
```

### 2. å®Œæ•´æ•°æ®æµä½¿ç”¨
```python
# å®Œæ•´çš„å¤„ç†é“¾
def process_traffic_data(data):
    """
    Args:
        data: (B, N, L, C) äº¤é€šæ•°æ®
    Returns:
        enhanced_features: (B, N, P, D) å¢å¼ºç‰¹å¾
        adjacency: (B, N, N) å­¦ä¹ çš„å›¾ç»“æ„
    """
    
    # Step 1: Patch Embedding
    patch_embed = PatchEmbedding(12, 1, 96, None)
    patches = patch_embed(data)  # (B, N, P, d)
    
    # Step 2: Dynamic Graph Learning  
    graph_conv = PostPatchDynamicGraphConv(96, 358, 10, graph_heads=4, topk=6, dropout=0.1)
    enhanced_patches, learned_adj = graph_conv(patches)
    
    return enhanced_patches, learned_adj
```

### 3. å…³é”®å‚æ•°è¯´æ˜
```python
# è¾“å…¥ç»´åº¦å«ä¹‰
B = batch_size    # æ‰¹æ¬¡å¤§å°
N = num_nodes     # èŠ‚ç‚¹æ•°é‡ (å¦‚358ä¸ªäº¤é€šä¼ æ„Ÿå™¨)
L = time_length   # æ—¶é—´åºåˆ—é•¿åº¦ (å¦‚864ä¸ªæ—¶é—´æ­¥)
C = channels      # ç‰¹å¾é€šé“æ•° (å¦‚1ç»´æµé‡æ•°æ®)

# è¾“å‡ºç»´åº¦å«ä¹‰  
P = num_patches   # patchæ•°é‡ = L // patch_size
d = embed_dim     # åµŒå…¥ç»´åº¦ (å¦‚96)
```

## âœ¨ æ€»ç»“

é€šè¿‡é€‚é…è¾“å…¥æ ¼å¼ä¸º`(B, N, L, C)`ï¼Œæˆ‘ä»¬å®ç°äº†ï¼š

1. **âœ… çœŸå®æ•°æ®æ ¼å¼åŒ¹é…**: ä¸å®é™…è¾“å…¥æ•°æ®å®Œç¾å¯¹åº”
2. **âœ… è‡ªåŠ¨æ ¼å¼è½¬æ¢**: å†…éƒ¨é€æ˜å¤„ç†ç»´åº¦è½¬æ¢
3. **âœ… è¾“å‡ºæ ¼å¼ç»Ÿä¸€**: ä¿æŒ`(B, N, P, d)`è¾“å‡ºæ ¼å¼  
4. **âœ… æ¨¡å—å®Œç¾å…¼å®¹**: ä¸æ‰€æœ‰ä¸‹æ¸¸ç»„ä»¶æ— ç¼å¯¹æ¥
5. **âœ… æ€§èƒ½ä¿æŒä¼˜å¼‚**: ç»´æŒ12å€æ•ˆç‡æå‡ä¼˜åŠ¿

ç°åœ¨PatchEmbeddingèƒ½å¤Ÿæ­£ç¡®å¤„ç†çœŸå®çš„äº¤é€šæ•°æ®è¾“å…¥æ ¼å¼ï¼Œä¸ºæ•´ä¸ªAGPSTæ¨¡å‹æä¾›äº†å¯é çš„åŸºç¡€ï¼ğŸš€

## ğŸ“‹ æ•°æ®æµæ¦‚è§ˆ

```
çœŸå®äº¤é€šæ•°æ®è¾“å…¥
     â†“
(B, N, L, C) = (4, 358, 864, 1)
     â†“ PatchEmbedding [è‡ªåŠ¨è½¬æ¢ + å·ç§¯]
(B, N, P, d) = (4, 358, 72, 96) 
     â†“ PostPatchDynamicGraphConv
(B, N, P, D) + adj(B, N, N) = (4, 358, 72, 96) + (4, 358, 358)
     â†“ åç»­Transformerå¤„ç†
æœ€ç»ˆè¾“å‡º
```

å®Œæ•´çš„ç«¯åˆ°ç«¯å¤„ç†é“¾ç°åœ¨å®Œå…¨å°±ç»ªï¼âœ¨