"""
æµ‹è¯•graph_headså‚æ•°é‡å‘½å
éªŒè¯æ–°å‚æ•°åæ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import torch
from basicts.mask.post_patch_adaptive_graph import PostPatchDynamicGraphConv

def test_graph_heads_parameter():
    """æµ‹è¯•graph_headså‚æ•°é‡å‘½å"""
    
    print("=== æµ‹è¯•graph_headså‚æ•°é‡å‘½å ===")
    
    # æµ‹è¯•ä¸åŒçš„graph_headså€¼
    test_configs = [
        {"graph_heads": 1, "desc": "å•å¤´"},
        {"graph_heads": 4, "desc": "4å¤´"},  
        {"graph_heads": 8, "desc": "8å¤´"}
    ]
    
    for config in test_configs:
        graph_heads = config["graph_heads"]
        desc = config["desc"]
        
        print(f"\næµ‹è¯•é…ç½®: {desc} (graph_heads={graph_heads})")
        
        try:
            # åˆ›å»ºåŠ¨æ€å›¾å­¦ä¹ æ¨¡å—
            dynamic_graph = PostPatchDynamicGraphConv(
                embed_dim=96,
                num_nodes=358,
                node_dim=10,
                graph_heads=graph_heads,  # ä½¿ç”¨æ–°çš„å‚æ•°å
                topk=6,
                dropout=0.1
            )
            
            print(f"  âœ… æ¨¡å—åˆ›å»ºæˆåŠŸ")
            
            # æµ‹è¯•å‰å‘ä¼ æ’­
            test_data = torch.randn(4, 358, 72, 96)  # (B, N, P, D)
            
            with torch.no_grad():
                enhanced_patches, learned_adj = dynamic_graph(test_data)
            
            print(f"  âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
            print(f"     è¾“å‡ºå½¢çŠ¶: {enhanced_patches.shape}")
            print(f"     é‚»æ¥çŸ©é˜µ: {learned_adj.shape}")
            
            # éªŒè¯å†…éƒ¨å‚æ•°
            graph_learner = dynamic_graph.graph_learner
            print(f"  âœ… å†…éƒ¨å‚æ•°æ£€æŸ¥:")
            print(f"     graph_heads: {graph_learner.graph_heads}")
            print(f"     static_embeddings1: {graph_learner.static_node_embeddings1.shape}")
            print(f"     temperature: {graph_learner.temperature.shape}")
            
        except Exception as e:
            print(f"  âŒ æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    return True

def test_parameter_conflicts():
    """æµ‹è¯•å‚æ•°åå†²çªè§£å†³"""
    
    print(f"\n=== æµ‹è¯•å‚æ•°åå†²çªè§£å†³ ===")
    
    # æ¨¡æ‹ŸTransformerçš„num_headså’Œå›¾å­¦ä¹ çš„graph_heads
    transformer_config = {
        "num_heads": 8,      # Transformerçš„å¤šå¤´æ³¨æ„åŠ›
        "graph_heads": 4,    # å›¾å­¦ä¹ çš„å¤šå¤´
    }
    
    print(f"é…ç½®å‚æ•°:")
    print(f"  Transformer num_heads: {transformer_config['num_heads']}")
    print(f"  Graph learning graph_heads: {transformer_config['graph_heads']}")
    
    try:
        # åˆ›å»ºå›¾å­¦ä¹ æ¨¡å—
        dynamic_graph = PostPatchDynamicGraphConv(
            embed_dim=96,
            num_nodes=358, 
            node_dim=10,
            graph_heads=transformer_config['graph_heads'],  # ä½¿ç”¨å›¾å­¦ä¹ ä¸“ç”¨å‚æ•°
            topk=6,
            dropout=0.1
        )
        
        print(f"  âœ… å‚æ•°åŒºåˆ†æˆåŠŸï¼Œæ— å†²çª")
        print(f"     å›¾å­¦ä¹ ä½¿ç”¨: graph_heads={transformer_config['graph_heads']}")
        print(f"     Transformerå¯ä»¥ç‹¬ç«‹ä½¿ç”¨: num_heads={transformer_config['num_heads']}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ å‚æ•°å†²çªæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_yaml_config_compatibility():
    """æµ‹è¯•YAMLé…ç½®å…¼å®¹æ€§"""
    
    print(f"\n=== æµ‹è¯•YAMLé…ç½®å…¼å®¹æ€§ ===")
    
    # æ¨¡æ‹ŸYAMLé…ç½®
    yaml_config = {
        "num_heads": 4,       # Transformer heads
        "graph_heads": 4,     # Graph learning heads  
        "embed_dim": 96,
        "num_nodes": 358,
        "node_dim": 10,
        "topk": 6,
        "dropout": 0.1
    }
    
    print(f"æ¨¡æ‹ŸYAMLé…ç½®:")
    for key, value in yaml_config.items():
        print(f"  {key}: {value}")
    
    try:
        # ä½¿ç”¨é…ç½®åˆ›å»ºæ¨¡å—
        dynamic_graph = PostPatchDynamicGraphConv(
            embed_dim=yaml_config["embed_dim"],
            num_nodes=yaml_config["num_nodes"],
            node_dim=yaml_config["node_dim"],
            graph_heads=yaml_config["graph_heads"],  # æ³¨æ„ä½¿ç”¨æ­£ç¡®çš„å‚æ•°å
            topk=yaml_config["topk"],
            dropout=yaml_config["dropout"]
        )
        
        print(f"  âœ… YAMLé…ç½®åŠ è½½æˆåŠŸ")
        print(f"  âœ… å‚æ•°åæ˜ å°„æ­£ç¡®")
        
        return True
        
    except Exception as e:
        print(f"  âŒ YAMLé…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯•graph_headså‚æ•°é‡å‘½å")
    print("=" * 60)
    
    # æµ‹è¯•åŸºæœ¬åŠŸèƒ½
    basic_test = test_graph_heads_parameter()
    
    # æµ‹è¯•å‚æ•°å†²çªè§£å†³
    conflict_test = test_parameter_conflicts()
    
    # æµ‹è¯•YAMLå…¼å®¹æ€§
    yaml_test = test_yaml_config_compatibility()
    
    print("\n" + "=" * 60)
    if basic_test and conflict_test and yaml_test:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        print("âœ… graph_headså‚æ•°é‡å‘½åæˆåŠŸ")
        print("âœ… è§£å†³äº†ä¸Transformer num_headsçš„å†²çª")
        print("âœ… YAMLé…ç½®å…¼å®¹æ€§è‰¯å¥½")
        
        print(f"\nğŸ“ ä½¿ç”¨è¯´æ˜:")
        print(f"  - Transformerå¤šå¤´æ³¨æ„åŠ›: num_heads")
        print(f"  - å›¾å­¦ä¹ å¤šå¤´æœºåˆ¶: graph_heads")
        print(f"  - ä¸¤ä¸ªå‚æ•°å¯ä»¥ç‹¬ç«‹è®¾ç½®ï¼Œäº’ä¸å¹²æ‰°")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç ")