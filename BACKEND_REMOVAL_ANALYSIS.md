# GraphWaveNet åç«¯ç§»é™¤å¯è¡Œæ€§åˆ†æ

## å½“å‰æ¶æ„å›é¡¾

### ç°æœ‰æµç¨‹
```
è¾“å…¥ (B, 12, N, 1)
  â†“
å»å™ªæ¨¡å— (å¯é€‰)
  â†“
æ—¶é—´ç‰¹å¾åµŒå…¥ (Linear: 1 â†’ 96)
  â†“
ä½ç½®ç¼–ç 
  â†“
è‡ªé€‚åº”å›¾å­¦ä¹  + åŠ¨æ€å›¾å·ç§¯
  â†“
Transformerç¼–ç å™¨ (12å±‚)
  â†“
GraphWaveNetåç«¯ (æå–é¢„æµ‹)
  â†“
è¾“å‡º (B, 12, N, 1)
```

### GraphWaveNet çš„ä½œç”¨

**æ ¸å¿ƒåŠŸèƒ½**:
1. **æ—¶ç©ºç‰¹å¾èåˆ**: ä½¿ç”¨ WaveNet æ¶æ„çš„æ—¶åºå·ç§¯ + GCN è¿›è¡Œæ—¶ç©ºè”åˆå»ºæ¨¡
2. **å¤šå°ºåº¦æ„Ÿå—é‡**: é€šè¿‡ dilated convolution (è†¨èƒ€å·ç§¯) æ•è·ä¸åŒæ—¶é—´å°ºåº¦çš„æ¨¡å¼
3. **æ®‹å·®è¿æ¥**: skip connections èåˆå¤šå±‚ç‰¹å¾
4. **éšè—çŠ¶æ€æ³¨å…¥**: å°† Transformer çš„è¾“å‡º `hidden_states` æ³¨å…¥åˆ°æœ€åçš„é¢„æµ‹å±‚
5. **æœ€ç»ˆé¢„æµ‹å¤´**: å°†ç‰¹å¾æ˜ å°„ä¸º 12 æ­¥é¢„æµ‹

**è¾“å…¥è¦æ±‚**:
- `input`: (B, L, N, C) - åŸå§‹å†å²æ•°æ®
- `hidden_states`: (B, N, D) - Transformer æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º (D=96)

**è¾“å‡º**:
- `prediction`: (B, N, 12) - 12 æ­¥æœªæ¥é¢„æµ‹

## ç§»é™¤ GraphWaveNet çš„å¯è¡Œæ€§

### âœ… **å®Œå…¨å¯è¡Œ**

åŸå› :
1. **å·²æœ‰è¶³å¤Ÿçš„æ—¶ç©ºå»ºæ¨¡èƒ½åŠ›**:
   - åŠ¨æ€å›¾å·ç§¯å·²ç»å¤„ç†äº†ç©ºé—´ä¾èµ–
   - Transformer å·²ç»å»ºæ¨¡äº†æ—¶é—´ä¾èµ–
   - è¿™ä¸¤ä¸ªæ¨¡å—å·²ç»æä¾›äº†å¼ºå¤§çš„æ—¶ç©ºè¡¨å¾å­¦ä¹ èƒ½åŠ›

2. **å¯ä»¥ç”¨ç®€å•é¢„æµ‹å¤´æ›¿ä»£**:
   - GraphWaveNet æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªå¤æ‚çš„é¢„æµ‹å¤´
   - å¯ä»¥ç”¨æ›´è½»é‡çº§çš„ MLP æˆ–å·ç§¯å±‚æ›¿ä»£

3. **å‡å°‘æ¨¡å‹å¤æ‚åº¦**:
   - GraphWaveNet æœ‰å¤§é‡å‚æ•° (WaveNet layers + GCN layers)
   - ç§»é™¤åæ¨¡å‹æ›´ç®€æ´ï¼Œè®­ç»ƒæ›´å¿«

## æ›¿ä»£æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: ç®€å• MLP é¢„æµ‹å¤´ (æ¨è)

```python
# æ›¿ä»£ self.backend = GraphWaveNet(...)
self.prediction_head = nn.Sequential(
    nn.Linear(embed_dim, embed_dim * 2),
    nn.ReLU(),
    nn.Dropout(dropout),
    nn.Linear(embed_dim * 2, 12)  # é¢„æµ‹12æ­¥
)
```

**Forward è°ƒæ•´**:
```python
# Step 5 ä¹‹å: x çš„å½¢çŠ¶æ˜¯ (B, N, T, D)
# ä½¿ç”¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„ç‰¹å¾
x_last = x[:, :, -1, :]  # (B, N, D)

# MLP é¢„æµ‹
prediction = self.prediction_head(x_last)  # (B, N, 12)

# è½¬æ¢è¾“å‡ºæ ¼å¼
prediction = prediction.permute(0, 2, 1).unsqueeze(-1)  # (B, 12, N, 1)
```

**ä¼˜ç‚¹**:
- âœ… ç®€å•ç›´æ¥
- âœ… å‚æ•°é‡å°‘
- âœ… è®­ç»ƒå¿«é€Ÿ
- âœ… æ˜“äºç†è§£

**ç¼ºç‚¹**:
- âŒ å¯èƒ½è¡¨è¾¾èƒ½åŠ›ç¨å¼±


### æ–¹æ¡ˆ 2: å·ç§¯é¢„æµ‹å¤´

```python
self.prediction_head = nn.Sequential(
    nn.Conv1d(embed_dim, embed_dim * 2, kernel_size=3, padding=1),
    nn.ReLU(),
    nn.Dropout(dropout),
    nn.Conv1d(embed_dim * 2, 12, kernel_size=1)  # 1x1å·ç§¯è¾“å‡º12æ­¥
)
```

**Forward è°ƒæ•´**:
```python
# ä½¿ç”¨æ‰€æœ‰æ—¶é—´æ­¥çš„ç‰¹å¾
x_spatial = x.mean(dim=2)  # ç©ºé—´ç»´åº¦å¹³å‡: (B, N, T, D) -> (B, N, D)
# æˆ–è€…ç›´æ¥ç”¨æœ€åå‡ ä¸ªæ—¶é—´æ­¥
x_temporal = x[:, :, -3:, :].mean(dim=2)  # (B, N, D)

# è½¬ç½®ä»¥é€‚é…Conv1d: (B, N, D) -> (B, D, N)
x_conv = x_spatial.permute(0, 2, 1)

# å·ç§¯é¢„æµ‹
prediction = self.prediction_head(x_conv)  # (B, 12, N)

# è½¬æ¢è¾“å‡ºæ ¼å¼
prediction = prediction.permute(0, 2, 1).unsqueeze(-1)  # (B, N, 12) -> (B, 12, N, 1)
```

**ä¼˜ç‚¹**:
- âœ… åˆ©ç”¨ç©ºé—´ç›¸å…³æ€§
- âœ… æ¯” MLP è¡¨è¾¾èƒ½åŠ›æ›´å¼º
- âœ… é€‚åˆåºåˆ—é¢„æµ‹

**ç¼ºç‚¹**:
- âŒ ç¨å¤æ‚


### æ–¹æ¡ˆ 3: æ—¶ç©ºè§£ç å™¨ (æœ€å¼ºå¤§)

```python
# æ—¶ç©ºè§£ç å™¨
self.decoder = nn.TransformerDecoder(
    nn.TransformerDecoderLayer(
        d_model=embed_dim,
        nhead=num_heads,
        dim_feedforward=embed_dim * mlp_ratio,
        dropout=dropout,
        batch_first=True
    ),
    num_layers=2
)

# é¢„æµ‹å¤´
self.prediction_head = nn.Linear(embed_dim, 1)

# å¯å­¦ä¹ çš„æŸ¥è¯¢å‘é‡ (ä»£è¡¨æœªæ¥12æ­¥)
self.future_queries = nn.Parameter(torch.randn(12, embed_dim))
```

**Forward è°ƒæ•´**:
```python
# x: (B, N, T, D)
B, N, T, D = x.shape

# å‡†å¤‡æŸ¥è¯¢å‘é‡: (12, D) -> (B*N, 12, D)
queries = self.future_queries.unsqueeze(0).expand(B * N, -1, -1)

# å‡†å¤‡è®°å¿†å‘é‡: (B, N, T, D) -> (B*N, T, D)
memory = x.reshape(B * N, T, D)

# è§£ç å™¨
decoded = self.decoder(queries, memory)  # (B*N, 12, D)

# é¢„æµ‹
prediction = self.prediction_head(decoded)  # (B*N, 12, 1)

# é‡å¡‘
prediction = prediction.reshape(B, N, 12, 1).permute(0, 2, 1, 3)  # (B, 12, N, 1)
```

**ä¼˜ç‚¹**:
- âœ… æœ€å¼ºå¤§çš„è¡¨è¾¾èƒ½åŠ›
- âœ… æ˜ç¡®å»ºæ¨¡å†å²-æœªæ¥å…³ç³»
- âœ… å¯ä»¥æ•è·å¤æ‚çš„æ—¶åºæ¨¡å¼

**ç¼ºç‚¹**:
- âŒ å‚æ•°é‡è¾ƒå¤š
- âŒ è®­ç»ƒæ—¶é—´è¾ƒé•¿


## æ¨èæ–¹æ¡ˆ

### ğŸ¯ **æ¨è: æ–¹æ¡ˆ 1 (ç®€å• MLP)**

**ç†ç”±**:
1. ä½ çš„æ¨¡å‹å·²ç»æœ‰:
   - å»å™ªæ¨¡å— â†’ æ•°æ®è´¨é‡é«˜
   - åŠ¨æ€å›¾å·ç§¯ â†’ å¼ºå¤§çš„ç©ºé—´å»ºæ¨¡
   - Transformer â†’ å¼ºå¤§çš„æ—¶é—´å»ºæ¨¡
   
2. è¿™äº›æ¨¡å—å·²ç»æå–äº†é«˜è´¨é‡çš„æ—¶ç©ºç‰¹å¾ï¼Œç®€å•çš„ MLP è¶³ä»¥å®Œæˆé¢„æµ‹

3. å¥¥å¡å§†å‰ƒåˆ€åŸåˆ™: åœ¨æ•ˆæœç›¸è¿‘çš„æƒ…å†µä¸‹ï¼Œé€‰æ‹©æœ€ç®€å•çš„æ–¹æ¡ˆ

### å®ç°ç¤ºä¾‹

```python
class AGPSTModel(nn.Module):
    def __init__(self, num_nodes, dim, topK, in_channel, embed_dim, 
                 num_heads, mlp_ratio, dropout, encoder_depth,
                 use_denoising=True, denoise_type='conv',
                 use_advanced_graph=True, graph_heads=4):
        super().__init__()
        
        # ... å…¶ä»–æ¨¡å—ä¿æŒä¸å˜ ...
        
        # æ›¿æ¢ GraphWaveNet ä¸ºç®€å•é¢„æµ‹å¤´
        self.prediction_head = nn.Sequential(
            nn.Linear(embed_dim, embed_dim * 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(embed_dim * 2, embed_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(embed_dim, 12)  # é¢„æµ‹12æ­¥
        )
        
    def forward(self, history_data):
        # ... å‰é¢çš„å¤„ç†ä¿æŒä¸å˜ï¼Œç›´åˆ° Transformer ...
        
        # Step 5: Transformeræ—¶åºå»ºæ¨¡
        BN, T, D = B * N, x.size(2), x.size(3)
        x_flat = x.reshape(BN, T, D)
        x_flat = self.transformer(x_flat)  # (B*N, T, D)
        x = x_flat.reshape(B, N, T, D)  # (B, N, T, D)
        
        # Step 6: æå–æœ€åæ—¶é—´æ­¥ç‰¹å¾
        x_last = x[:, :, -1, :]  # (B, N, D)
        
        # Step 7: MLP é¢„æµ‹
        prediction = self.prediction_head(x_last)  # (B, N, 12)
        
        # Step 8: è½¬æ¢è¾“å‡ºæ ¼å¼
        prediction = prediction.permute(0, 2, 1).unsqueeze(-1)  # (B, 12, N, 1)
        
        return prediction
```

## æ€§èƒ½å¯¹æ¯”é¢„æµ‹

| æ–¹æ¡ˆ | å‚æ•°é‡ | è®­ç»ƒé€Ÿåº¦ | é¢„æµ‹èƒ½åŠ› | å¤æ‚åº¦ |
|------|--------|---------|---------|--------|
| GraphWaveNet | å¾ˆå¤§ | æ…¢ | å¼º | é«˜ |
| ç®€å• MLP | å° | å¿« | ä¸­-å¼º | ä½ |
| å·ç§¯å¤´ | ä¸­ | ä¸­ | ä¸­-å¼º | ä¸­ |
| Transformerè§£ç å™¨ | å¤§ | æ…¢ | å¾ˆå¼º | é«˜ |

## å®éªŒå»ºè®®

### ç¬¬ä¸€é˜¶æ®µ: ç®€å•æ›¿æ¢
1. ç”¨æ–¹æ¡ˆ1æ›¿æ¢ GraphWaveNet
2. è®­ç»ƒå¹¶è§‚å¯Ÿæ€§èƒ½
3. å¦‚æœæ€§èƒ½ä¸‹é™ä¸æ˜æ˜¾ (< 5%) â†’ æˆåŠŸï¼Œä¿æŒç®€å•æ–¹æ¡ˆ

### ç¬¬äºŒé˜¶æ®µ: é€æ­¥å¢å¼º (å¦‚æœéœ€è¦)
1. å¦‚æœæ€§èƒ½ä¸‹é™æ˜æ˜¾ â†’ å°è¯•æ–¹æ¡ˆ2 (å·ç§¯å¤´)
2. å¦‚æœä»ä¸å¤Ÿ â†’ å°è¯•æ–¹æ¡ˆ3 (Transformerè§£ç å™¨)
3. å¦‚æœè¿˜ä¸å¤Ÿ â†’ ä¿ç•™ GraphWaveNet

## æ€»ç»“

âœ… **ç§»é™¤ GraphWaveNet å®Œå…¨å¯è¡Œ**

**æ ¸å¿ƒé€»è¾‘**:
- ä½ çš„æ¨¡å‹å·²ç»æœ‰å¼ºå¤§çš„ç‰¹å¾æå–èƒ½åŠ› (å»å™ª + å›¾å­¦ä¹  + Transformer)
- é¢„æµ‹å¤´åªéœ€è¦å°†è¿™äº›ç‰¹å¾æ˜ å°„åˆ°è¾“å‡ºç©ºé—´
- ç®€å•çš„ MLP é€šå¸¸å°±è¶³å¤Ÿäº†

**å»ºè®®è¡ŒåŠ¨**:
1. âœ… å…ˆå°è¯•æœ€ç®€å•çš„ MLP é¢„æµ‹å¤´
2. âœ… è§‚å¯Ÿè®­ç»ƒå’ŒéªŒè¯æ€§èƒ½
3. âœ… å¿…è¦æ—¶å†è€ƒè™‘æ›´å¤æ‚çš„æ–¹æ¡ˆ

**é¢„æœŸæ”¶ç›Š**:
- ğŸš€ æ¨¡å‹æ›´ç®€æ´
- ğŸš€ è®­ç»ƒé€Ÿåº¦æ›´å¿«  
- ğŸš€ å‚æ•°é‡å‡å°‘ 30-50%
- ğŸš€ æ›´å®¹æ˜“ç†è§£å’Œè°ƒè¯•
