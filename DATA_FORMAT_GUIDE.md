# æ•°æ®æ ¼å¼è¯´æ˜æ–‡æ¡£

## AGPST Direct Forecasting æ•°æ®æµ

### ğŸ“Š è¾“å…¥æ•°æ®æ ¼å¼

æ‰€æœ‰æ•°æ®é›†éµå¾ªç»Ÿä¸€æ ¼å¼ï¼š**`(B, T, N, C)`**

- **B**: Batch sizeï¼ˆæ‰¹æ¬¡å¤§å°ï¼‰
- **T**: Time stepsï¼ˆæ—¶é—´æ­¥æ•°ï¼‰
- **N**: Number of nodesï¼ˆèŠ‚ç‚¹æ•°é‡ï¼‰= 358ï¼ˆPEMS03æ•°æ®é›†ï¼‰
- **C**: Number of channels/featuresï¼ˆé€šé“/ç‰¹å¾æ•°ï¼‰= 1

### ğŸ”„ æ•°æ®æµè½¬æ¢

#### 1. DataLoader è¾“å‡º

```python
future_data, history_data, long_history_data = data

# æ•°æ®å½¢çŠ¶
history_data:      (B, 12, 358, 1)   # çŸ­æœŸå†å²
long_history_data: (B, 864, 358, 1)  # é•¿æœŸå†å²
future_data:       (B, 12, 358, 1)   # æœªæ¥çœŸå®å€¼ï¼ˆç”¨äºè®¡ç®—æŸå¤±ï¼‰
```

#### 2. ForecastingWithAdaptiveGraph å†…éƒ¨è½¬æ¢

```python
def forward(self, history_data, long_history_data, future_data, batch_seen, epoch):
    # Step 1: è½¬æ¢é•¿æœŸå†å²æ•°æ®ç”¨äº Patch Embedding
    # ä» (B, T, N, C) -> (B, N, T, C)
    long_history_data = long_history_data.transpose(1, 2)
    # ç»“æœ: (B, 358, 864, 1)
    
    # Step 2: Patch Embedding
    # è¾“å…¥: (B, N, T, C) = (B, 358, 864, 1)
    # è¾“å‡º: (B, N, P, D) = (B, 358, 72, 96)
    # å…¶ä¸­ P = 864/12 = 72 ä¸ªpatchï¼ŒD = embed_dim = 96
    patches = self.patch_embedding(long_history_data)
    
    # Step 3: Dynamic Graph Learning
    # è¾“å…¥/è¾“å‡º: (B, N, P, D) = (B, 358, 72, 96)
    patches, learned_adj, contrastive_loss = self.dynamic_graph_conv(patches)
    
    # Step 4: Positional Encoding + Transformer
    # è¾“å…¥/è¾“å‡º: (B, N, P, D) = (B, 358, 72, 96)
    patches, _ = self.positional_encoding(patches)
    hidden_states = self.encoder(patches)
    hidden_states = self.encoder_norm(hidden_states)
    
    # Step 5: æå–èŠ‚ç‚¹ç‰¹å¾
    # è¾“å…¥: (B, N, P, D) = (B, 358, 72, 96)
    # è¾“å‡º: (B, N, D) = (B, 358, 96)
    node_features = hidden_states[:, :, -1, :]  # å–æœ€åä¸€ä¸ªpatch
    node_features = self.output_adapter(node_features)
    
    # Step 6: GraphWaveNet é¢„æµ‹
    # è¾“å…¥1: history_data (B, T, N, C) = (B, 12, 358, 1)  [æœªè½¬æ¢ï¼Œä¿æŒåŸæ ¼å¼]
    # è¾“å…¥2: node_features (B, N, D) = (B, 358, 96)
    # è¾“å‡º: (B, N, L) = (B, 358, 12)
    y_hat = self.backend(history_data, hidden_states=node_features)
    
    # Step 7: è°ƒæ•´è¾“å‡ºæ ¼å¼
    # ä» (B, N, L) -> (B, L, N) -> (B, N, L, 1)
    y_hat = y_hat.transpose(1, 2).unsqueeze(-1)
    # æœ€ç»ˆè¾“å‡º: (B, 358, 12, 1)
```

#### 3. æŸå¤±è®¡ç®—

```python
# é¢„æµ‹å€¼å’ŒçœŸå®å€¼æ ¼å¼
preds:  (B, 358, 12, 1)  # æ¨¡å‹è¾“å‡º
labels: (B, 12, 358, 1)  # éœ€è¦è½¬æ¢ä¸º (B, 358, 12, 1) æˆ–è°ƒæ•´lossè®¡ç®—

# æ³¨æ„ï¼šå½“å‰ä»£ç ä¸­ labels = future_data ä¿æŒ (B, 12, 358, 1) æ ¼å¼
# éœ€è¦ç¡®ä¿ SCALER å’Œ metric å‡½æ•°èƒ½æ­£ç¡®å¤„ç†è¿™ä¸¤ç§æ ¼å¼
```

### âš ï¸ é‡è¦æ³¨æ„äº‹é¡¹

#### æ ¼å¼ä¸ä¸€è‡´é—®é¢˜

å½“å‰å­˜åœ¨ä¸€ä¸ª**æ½œåœ¨çš„æ ¼å¼ä¸åŒ¹é…**ï¼š

```python
# åœ¨ direct_forecasting() å‡½æ•°ä¸­
labels = future_data.to(args.device)  # (B, 12, 358, 1)
preds = model(...)                     # (B, 358, 12, 1)

# è¿™ä¸¤ä¸ªæ ¼å¼ä¸ä¸€è‡´ï¼
```

#### è§£å†³æ–¹æ¡ˆ

æœ‰ä¸¤ç§æ–¹æ¡ˆï¼š

**æ–¹æ¡ˆ 1: åœ¨æ¨¡å‹è¾“å‡ºåè½¬æ¢**
```python
# åœ¨ ForecastingWithAdaptiveGraph.forward() æœ€å
y_hat = y_hat.transpose(1, 2).unsqueeze(-1)  # (B, N, L, 1)
# æ”¹ä¸º
y_hat = y_hat.unsqueeze(-1)  # (B, N, L, 1) 
# ç„¶ååœ¨å¤–éƒ¨è½¬æ¢ä¸º (B, L, N, 1)
```

**æ–¹æ¡ˆ 2: åœ¨æŸå¤±è®¡ç®—å‰è½¬æ¢æ ‡ç­¾**
```python
# åœ¨ direct_forecasting() ä¸­
labels = future_data.transpose(1, 2).to(args.device)  # (B, 12, 358, 1) -> (B, 358, 12, 1)
```

### ğŸ¯ æ¨èçš„æ ‡å‡†åŒ–æ ¼å¼

å»ºè®®ç»Ÿä¸€ä½¿ç”¨ **`(B, L, N, C)`** ä½œä¸ºé¢„æµ‹è¾“å‡ºæ ¼å¼ï¼Œä¸æ•°æ®é›†æ ¼å¼ä¿æŒä¸€è‡´ï¼š

```python
class ForecastingWithAdaptiveGraph:
    def forward(...):
        # ... å‰é¢çš„å¤„ç† ...
        
        # GraphWaveNet è¾“å‡º (B, N, L)
        y_hat = self.backend(history_data, hidden_states=node_features)
        
        # è½¬æ¢ä¸º (B, L, N, 1) ä¸è¾“å…¥æ ¼å¼ä¸€è‡´
        y_hat = y_hat.permute(0, 2, 1).unsqueeze(-1)
        
        return y_hat  # (B, L, N, C)
```

### ğŸ“ å„æ¨¡å—æœŸæœ›çš„è¾“å…¥æ ¼å¼æ€»ç»“

| æ¨¡å— | è¾“å…¥æ ¼å¼ | è¾“å‡ºæ ¼å¼ |
|------|---------|---------|
| DataLoader | - | `(B, T, N, C)` |
| PatchEmbedding | `(B, N, T, C)` | `(B, N, P, D)` |
| DynamicGraphConv | `(B, N, P, D)` | `(B, N, P, D)` |
| Transformer | `(B, N, P, D)` | `(B, N, P, D)` |
| GraphWaveNet | `(B, T, N, C)` | `(B, N, L)` |
| æŸå¤±å‡½æ•° | `(B, L, N, C)` & `(B, L, N, C)` | scalar |

### ğŸ”§ è°ƒè¯•æ£€æŸ¥æ¸…å•

è¿è¡Œæ¨¡å‹æ—¶ï¼Œæ‰“å°ä»¥ä¸‹å½¢çŠ¶è¿›è¡ŒéªŒè¯ï¼š

```python
print(f"history_data: {history_data.shape}")           # åº”ä¸º (B, 12, 358, 1)
print(f"long_history_data: {long_history_data.shape}") # åº”ä¸º (B, 864, 358, 1)
print(f"future_data: {future_data.shape}")             # åº”ä¸º (B, 12, 358, 1)
print(f"preds: {preds.shape}")                         # åº”ä¸º (B, 12, 358, 1) æˆ– (B, 358, 12, 1)
```

### âœ… éªŒè¯ä»£ç 

```python
# åœ¨è®­ç»ƒå¾ªç¯ä¸­æ·»åŠ 
if idx == 0 and epoch == 0:
    print("=" * 50)
    print("Data Shape Verification:")
    print(f"  history_data: {history_data.shape}")
    print(f"  long_history_data (before): {long_history_data_orig.shape}")
    print(f"  long_history_data (after transpose): {long_history_data.shape}")
    print(f"  future_data (labels): {labels.shape}")
    print(f"  predictions: {preds.shape}")
    print("=" * 50)
```

---

**æ³¨æ„**: ç¡®ä¿æ‰€æœ‰ç»´åº¦è½¬æ¢éƒ½ç»è¿‡ä»”ç»†éªŒè¯ï¼Œé¿å…å‡ºç°ç»´åº¦ä¸åŒ¹é…å¯¼è‡´çš„è®­ç»ƒé”™è¯¯ï¼
