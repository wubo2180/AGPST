"""
å¿«é€Ÿæµ‹è¯•æ–°çš„æ¨¡å—æ¶æ„
"""
import sys
import torch

def test_imports():
    """æµ‹è¯•å¯¼å…¥"""
    print("=" * 60)
    print("æµ‹è¯•1: å¯¼å…¥æ¨¡å—")
    print("=" * 60)
    
    try:
        from basicts.mask import (
            AGPSTModel,
            ForecastingWithAdaptiveGraph,
            DynamicGraphConv,
            AdaptiveGraphLearner,
            PatchEmbedding,
            TransformerLayers,
            PositionalEncoding
        )
        print("âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ!")
        print(f"   - AGPSTModel: {AGPSTModel}")
        print(f"   - ForecastingWithAdaptiveGraph (alias): {ForecastingWithAdaptiveGraph}")
        return True
    except Exception as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False


def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•2: åˆ›å»ºæ¨¡å‹")
    print("=" * 60)
    
    try:
        from basicts.mask import AGPSTModel
        
        model = AGPSTModel(
            num_nodes=358,
            dim=10,
            topK=10,
            patch_size=12,
            in_channel=1,
            embed_dim=96,
            num_heads=4,
            graph_heads=4,
            mlp_ratio=4,
            dropout=0.1,
            encoder_depth=4,
            backend_args={
                'num_nodes': 358,
                'supports': None,
                'dropout': 0.3,
                'gcn_bool': True,
                'addaptadj': True,
                'aptinit': None,
                'in_dim': 96,
                'out_dim': 12,
                'residual_channels': 32,
                'dilation_channels': 32,
                'skip_channels': 256,
                'end_channels': 512,
                'kernel_size': 2,
                'blocks': 4,
                'layers': 2
            }
        )
        
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ!")
        print(f"   - æ€»å‚æ•°é‡: {total_params:,}")
        print(f"   - å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        print(f"   - å‚æ•°é‡ (MB): {total_params * 4 / 1024 / 1024:.2f}")
        
        return model
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_forward_pass(model):
    """æµ‹è¯•å‰å‘ä¼ æ’­"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•3: å‰å‘ä¼ æ’­")
    print("=" * 60)
    
    if model is None:
        print("âŒ è·³è¿‡ï¼ˆæ¨¡å‹æœªåˆ›å»ºï¼‰")
        return False
    
    try:
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        B, N, C = 2, 358, 1  # å°batchç”¨äºæµ‹è¯•
        short_len, long_len = 12, 864
        
        history_data = torch.randn(B, short_len, N, C)
        long_history_data = torch.randn(B, long_len, N, C)
        
        print(f"   è¾“å…¥æ•°æ®:")
        print(f"   - history_data: {history_data.shape}")
        print(f"   - long_history_data: {long_history_data.shape}")
        
        # å‰å‘ä¼ æ’­
        model.eval()
        with torch.no_grad():
            prediction = model(history_data, long_history_data)
        
        print(f"   è¾“å‡ºæ•°æ®:")
        print(f"   - prediction: {prediction.shape}")
        print(f"   - æœŸæœ›shape: (B={B}, T=12, N={N}, C={C})")
        
        # éªŒè¯shape
        expected_shape = (B, short_len, N, C)
        if prediction.shape == expected_shape:
            print("âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼Œè¾“å‡ºshapeæ­£ç¡®!")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰NaN
            if torch.isnan(prediction).any():
                print("âš ï¸  è­¦å‘Š: è¾“å‡ºåŒ…å«NaNå€¼")
                return False
            else:
                print("âœ… è¾“å‡ºæ•°æ®æ­£å¸¸ï¼ˆæ— NaNï¼‰")
                return True
        else:
            print(f"âŒ è¾“å‡ºshapeä¸åŒ¹é…: {prediction.shape} != {expected_shape}")
            return False
            
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_components():
    """æµ‹è¯•å„ä¸ªç»„ä»¶"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•4: ç‹¬ç«‹ç»„ä»¶")
    print("=" * 60)
    
    try:
        from basicts.mask import PatchEmbedding, DynamicGraphConv, TransformerLayers
        
        B, N, L, C = 2, 358, 864, 1
        
        # æµ‹è¯•PatchEmbedding
        print("   æµ‹è¯• PatchEmbedding...")
        patch_embed = PatchEmbedding(patch_size=12, in_channel=1, embed_dim=96)
        long_history = torch.randn(B, N, L, C)
        patches = patch_embed(long_history)
        print(f"   âœ… PatchEmbedding: {long_history.shape} â†’ {patches.shape}")
        
        # æµ‹è¯•DynamicGraphConv
        print("   æµ‹è¯• DynamicGraphConv...")
        graph_conv = DynamicGraphConv(embed_dim=96, num_nodes=N, node_dim=10)
        graph_features, adj, loss = graph_conv(patches)
        print(f"   âœ… DynamicGraphConv: {patches.shape} â†’ {graph_features.shape}")
        print(f"      - é‚»æ¥çŸ©é˜µ: {adj.shape}")
        print(f"      - å¯¹æ¯”æŸå¤±: {loss.item() if loss is not None else 'None'}")
        
        # æµ‹è¯•TransformerLayers
        print("   æµ‹è¯• TransformerLayers...")
        transformer = TransformerLayers(hidden_dim=96, nlayers=4, mlp_ratio=4)
        temporal_features = transformer(graph_features)
        print(f"   âœ… TransformerLayers: {graph_features.shape} â†’ {temporal_features.shape}")
        
        print("âœ… æ‰€æœ‰ç»„ä»¶æµ‹è¯•é€šè¿‡!")
        return True
        
    except Exception as e:
        print(f"âŒ ç»„ä»¶æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "ğŸ” AGPST æ¨¡å—æ¶æ„æµ‹è¯•" + "\n")
    
    results = {
        "å¯¼å…¥æµ‹è¯•": False,
        "æ¨¡å‹åˆ›å»º": False,
        "å‰å‘ä¼ æ’­": False,
        "ç»„ä»¶æµ‹è¯•": False
    }
    
    # æµ‹è¯•1: å¯¼å…¥
    results["å¯¼å…¥æµ‹è¯•"] = test_imports()
    
    # æµ‹è¯•2: æ¨¡å‹åˆ›å»º
    if results["å¯¼å…¥æµ‹è¯•"]:
        model = test_model_creation()
        results["æ¨¡å‹åˆ›å»º"] = model is not None
        
        # æµ‹è¯•3: å‰å‘ä¼ æ’­
        if results["æ¨¡å‹åˆ›å»º"]:
            results["å‰å‘ä¼ æ’­"] = test_forward_pass(model)
    
    # æµ‹è¯•4: ç»„ä»¶æµ‹è¯•
    if results["å¯¼å…¥æµ‹è¯•"]:
        results["ç»„ä»¶æµ‹è¯•"] = test_components()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
    
    all_passed = all(results.values())
    print("\n" + "=" * 60)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! æ–°æ¶æ„å·¥ä½œæ­£å¸¸!")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
    print("=" * 60)
    
    return 0 if all_passed else 1


if __name__ == "__main__":
    sys.exit(main())
