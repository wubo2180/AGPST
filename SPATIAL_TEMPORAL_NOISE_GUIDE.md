# ğŸŒ æ—¶ç©ºå™ªå£°åˆ†ææŒ‡å—

## ğŸ“Š æ—¶é—´ vs ç©ºé—´å™ªå£°åˆ†æ

### æ ¸å¿ƒåŒºåˆ«

| ç»´åº¦ | åˆ†æå¯¹è±¡ | å™ªå£°ç‰¹å¾ | æ£€æµ‹æ–¹æ³• |
|------|---------|---------|---------|
| **æ—¶é—´ç»´åº¦** | å•ä¸ªèŠ‚ç‚¹çš„æ—¶é—´åºåˆ— | æ—¶é—´çªå˜ã€å‘¨æœŸæ€§å¼‚å¸¸ | æ—¶é—´åºåˆ—åˆ†æ |
| **ç©ºé—´ç»´åº¦** | åŒä¸€æ—¶åˆ»çš„èŠ‚ç‚¹åˆ†å¸ƒ | ç©ºé—´å­¤ç«‹ç‚¹ã€åŒºåŸŸå¼‚å¸¸ | ç©ºé—´ç›¸å…³æ€§åˆ†æ |

---

## 1ï¸âƒ£ æ—¶é—´ç»´åº¦å™ªå£°ï¼ˆå½“å‰å®ç°ï¼‰

### åˆ†æå†…å®¹
```python
# æ•°æ®å½¢çŠ¶: (T, N)
# å¯¹æ¯ä¸ªèŠ‚ç‚¹ n âˆˆ [0, N-1]:
#   åˆ†æå…¶æ—¶é—´åºåˆ—: data[:, n]  # (T,)
```

### æ£€æµ‹ç›®æ ‡
```
èŠ‚ç‚¹içš„æµé‡å˜åŒ–
    â†‘
 80 |     *              â† æ—¶é—´å¼‚å¸¸å€¼ï¼ˆçªç„¶é£™å‡ï¼‰
    |    * *
 60 |   *   *
    | *       *
 40 |*         **
    |            **
 20 |              ***
    |â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ æ—¶é—´
```

### å™ªå£°ç±»å‹
1. **çªå˜å™ªå£°**: æµé‡çªç„¶å¤§å¹…å˜åŒ–
2. **é«˜é¢‘å™ªå£°**: å¿«é€ŸæŒ¯è¡
3. **è¶‹åŠ¿å¼‚å¸¸**: ä¸æ­£å¸¸æ¨¡å¼åç¦»
4. **å‘¨æœŸå¼‚å¸¸**: ç ´åæ­£å¸¸çš„æ—¥/å‘¨å‘¨æœŸ

### åº”ç”¨åœºæ™¯
- âœ… æ£€æµ‹ä¼ æ„Ÿå™¨æ•…éšœ
- âœ… å‘ç°ç‰¹æ®Šäº‹ä»¶ï¼ˆäº‹æ•…ã€æ–½å·¥ï¼‰
- âœ… è¯„ä¼°æ•°æ®é‡‡é›†è´¨é‡

---

## 2ï¸âƒ£ ç©ºé—´ç»´åº¦å™ªå£°ï¼ˆæ–°å¢åˆ†æï¼‰

### åˆ†æå†…å®¹
```python
# æ•°æ®å½¢çŠ¶: (T, N)
# å¯¹æ¯ä¸ªæ—¶åˆ» t âˆˆ [0, T-1]:
#   åˆ†æç©ºé—´åˆ†å¸ƒ: data[t, :]  # (N,)
```

### æ£€æµ‹ç›®æ ‡
```
æŸæ—¶åˆ»çš„ç©ºé—´åˆ†å¸ƒï¼ˆåœ°å›¾è§†å›¾ï¼‰
    
    èŠ‚ç‚¹å¸ƒå±€:
    1 - 2 - 3 - 4
    |   |   |   |
    5 - 6 - 7 - 8
    |   |   |   |
    9 -10 -11 -12
    
    æµé‡å€¼:
   50  52  48 120  â† èŠ‚ç‚¹4æ˜¯ç©ºé—´å¼‚å¸¸å€¼ï¼ˆå‘¨å›´éƒ½æ˜¯50å·¦å³ï¼Œå®ƒæ˜¯120ï¼‰
   51  49  51  50
   48  50  52  49
```

### ç©ºé—´å™ªå£°ç‰¹å¾

#### ç‰¹å¾1: ç©ºé—´å­¤ç«‹ç‚¹
```
æ­£å¸¸æƒ…å†µï¼ˆç©ºé—´è¿ç»­ï¼‰:
50 â†’ 52 â†’ 55 â†’ 58  (å¹³æ»‘å˜åŒ–)

å¼‚å¸¸æƒ…å†µï¼ˆç©ºé—´å­¤ç«‹ï¼‰:
50 â†’ 52 â†’ 120 â†’ 58  (èŠ‚ç‚¹3çªç„¶å¾ˆé«˜)
```

#### ç‰¹å¾2: åŒºåŸŸå¼‚å¸¸
```
æ­£å¸¸åŒºåŸŸ:
50  52  48  51
49  51  50  52

å¼‚å¸¸åŒºåŸŸ:
50  52  48  51
49   5   3  52  â† ä¸­é—´åŒºåŸŸå¼‚å¸¸ä½
```

#### ç‰¹å¾3: ç©ºé—´ä¸è¿ç»­
```
ç†è®ºä¸Šç›¸é‚»èŠ‚ç‚¹åº”è¯¥æµé‡ç›¸ä¼¼
å¦‚æœ |flow[i] - flow[neighbor(i)]| å¾ˆå¤§ â†’ ç©ºé—´å™ªå£°
```

### å™ªå£°ç±»å‹

1. **ç©ºé—´å­¤ç«‹å™ªå£°**
   - å•ä¸ªèŠ‚ç‚¹ä¸å‘¨å›´èŠ‚ç‚¹å·®å¼‚å¤§
   - å¯èƒ½åŸå› : ä¼ æ„Ÿå™¨æ•…éšœã€æ•°æ®ä¼ è¾“é”™è¯¯

2. **ç©ºé—´èšç±»å™ªå£°**
   - æŸä¸ªåŒºåŸŸæ•´ä½“å¼‚å¸¸
   - å¯èƒ½åŸå› : åŒºåŸŸæ€§äº‹ä»¶ï¼ˆæ–½å·¥ã€å°è·¯ï¼‰

3. **ç©ºé—´ä¸è¿ç»­å™ªå£°**
   - ç›¸é‚»èŠ‚ç‚¹æµé‡å·®å¼‚è¿‡å¤§
   - è¿åç©ºé—´å¹³æ»‘æ€§å‡è®¾

---

## 3ï¸âƒ£ ç©ºé—´å™ªå£°æ£€æµ‹æ–¹æ³•

### æ–¹æ³•1: ç©ºé—´è‡ªç›¸å…³ï¼ˆMoran's Iï¼‰

```python
def compute_spatial_autocorrelation(data, adj_matrix):
    """
    è®¡ç®—ç©ºé—´è‡ªç›¸å…³ç³»æ•°
    
    Args:
        data: (T, N) æ—¶ç©ºæ•°æ®
        adj_matrix: (N, N) é‚»æ¥çŸ©é˜µ
    
    Returns:
        moran_i: ç©ºé—´è‡ªç›¸å…³ç³»æ•°
        - æ¥è¿‘1: æ­£ç›¸å…³ï¼ˆç›¸é‚»èŠ‚ç‚¹ç›¸ä¼¼ï¼‰âœ… æ­£å¸¸
        - æ¥è¿‘0: æ— ç›¸å…³ âš ï¸ å¯ç–‘
        - æ¥è¿‘-1: è´Ÿç›¸å…³ï¼ˆç›¸é‚»èŠ‚ç‚¹ç›¸åï¼‰âŒ å¼‚å¸¸
    """
    T, N = data.shape
    moran_values = []
    
    for t in range(T):
        snapshot = data[t, :]  # (N,)
        mean_val = np.mean(snapshot)
        
        # æ ‡å‡†åŒ–
        deviations = snapshot - mean_val
        
        # è®¡ç®—Moran's I
        numerator = 0
        denominator = np.sum(deviations ** 2)
        W = np.sum(adj_matrix)  # æ€»æƒé‡
        
        for i in range(N):
            for j in range(N):
                numerator += adj_matrix[i, j] * deviations[i] * deviations[j]
        
        moran_i = (N / W) * (numerator / denominator)
        moran_values.append(moran_i)
    
    return np.array(moran_values)
```

**è§£é‡Š**:
- **é«˜Moran's I** (>0.5): ç©ºé—´å¹³æ»‘ï¼Œç›¸é‚»èŠ‚ç‚¹ç›¸ä¼¼ â†’ æ•°æ®è´¨é‡å¥½
- **ä½Moran's I** (<0.2): ç©ºé—´æ··ä¹±ï¼Œéšæœºåˆ†å¸ƒ â†’ å¯èƒ½æœ‰å™ªå£°

---

### æ–¹æ³•2: ç©ºé—´æ¢¯åº¦å¼‚å¸¸æ£€æµ‹

```python
def detect_spatial_gradient_outliers(data, adj_matrix, threshold=3.0):
    """
    æ£€æµ‹ç©ºé—´æ¢¯åº¦å¼‚å¸¸
    
    åŸç†: ç›¸é‚»èŠ‚ç‚¹æµé‡å·®å¼‚ä¸åº”å¤ªå¤§
    """
    T, N = data.shape
    spatial_outliers = np.zeros((T, N), dtype=bool)
    
    for t in range(T):
        snapshot = data[t, :]  # (N,)
        
        for i in range(N):
            # æ‰¾åˆ°èŠ‚ç‚¹içš„é‚»å±…
            neighbors = np.where(adj_matrix[i, :] > 0)[0]
            
            if len(neighbors) == 0:
                continue
            
            # è®¡ç®—ä¸é‚»å±…çš„å¹³å‡å·®å¼‚
            neighbor_vals = snapshot[neighbors]
            avg_neighbor = np.mean(neighbor_vals)
            
            # è®¡ç®—Z-score
            std_neighbor = np.std(neighbor_vals)
            if std_neighbor > 0:
                z_score = abs(snapshot[i] - avg_neighbor) / std_neighbor
                
                if z_score > threshold:
                    spatial_outliers[t, i] = True
    
    return spatial_outliers
```

**ç¤ºä¾‹**:
```
èŠ‚ç‚¹5åŠå…¶é‚»å±…:
  2 (flow=50)
  |
4-5-6  (flow=48, ?, 52)
  |
  8 (flow=51)

å¦‚æœ flow[5] = 120:
  é‚»å±…å¹³å‡ = (50+48+52+51)/4 = 50.25
  å·®å¼‚ = |120 - 50.25| = 69.75
  æ ‡å‡†å·® = 1.7
  Z-score = 69.75/1.7 = 41 >> 3 âŒ ç©ºé—´å¼‚å¸¸ï¼
```

---

### æ–¹æ³•3: å±€éƒ¨ç¦»ç¾¤å› å­ï¼ˆLOFï¼‰

```python
from sklearn.neighbors import LocalOutlierFactor

def detect_spatial_lof(data, n_neighbors=5):
    """
    ä½¿ç”¨LOFæ£€æµ‹ç©ºé—´å¼‚å¸¸å€¼
    
    åŸç†: æ¯”è¾ƒèŠ‚ç‚¹å¯†åº¦ä¸å…¶é‚»å±…çš„å¯†åº¦
    """
    T, N = data.shape
    lof_scores = np.zeros((T, N))
    
    for t in range(T):
        snapshot = data[t, :].reshape(-1, 1)  # (N, 1)
        
        lof = LocalOutlierFactor(n_neighbors=n_neighbors)
        scores = lof.fit_predict(snapshot)
        
        # -1è¡¨ç¤ºå¼‚å¸¸å€¼
        lof_scores[t, :] = lof.negative_outlier_factor_
    
    # é˜ˆå€¼: é€šå¸¸ < -1.5 è®¤ä¸ºæ˜¯å¼‚å¸¸
    spatial_outliers = lof_scores < -1.5
    
    return spatial_outliers, lof_scores
```

---

## 4ï¸âƒ£ æ—¶ç©ºè”åˆå™ªå£°åˆ†æ

### ç»¼åˆæŒ‡æ ‡

```python
def comprehensive_noise_analysis(data, adj_matrix):
    """
    æ—¶ç©ºè”åˆå™ªå£°åˆ†æ
    
    Returns:
        metrics: åŒ…å«æ—¶é—´å’Œç©ºé—´å™ªå£°æŒ‡æ ‡
    """
    T, N = data.shape
    
    # 1. æ—¶é—´ç»´åº¦åˆ†æï¼ˆåŸæœ‰ï¼‰
    temporal_outliers = detect_temporal_outliers(data)  # (T, N)
    temporal_ratio = temporal_outliers.sum() / temporal_outliers.size * 100
    
    # 2. ç©ºé—´ç»´åº¦åˆ†æï¼ˆæ–°å¢ï¼‰
    spatial_outliers = detect_spatial_gradient_outliers(data, adj_matrix)  # (T, N)
    spatial_ratio = spatial_outliers.sum() / spatial_outliers.size * 100
    
    # 3. æ—¶ç©ºäº¤å‰å¼‚å¸¸ï¼ˆåŒæ—¶æ˜¯æ—¶é—´å’Œç©ºé—´å¼‚å¸¸ï¼‰
    spatiotemporal_outliers = temporal_outliers & spatial_outliers
    st_ratio = spatiotemporal_outliers.sum() / spatiotemporal_outliers.size * 100
    
    # 4. ç©ºé—´è‡ªç›¸å…³
    moran_i = compute_spatial_autocorrelation(data, adj_matrix)
    avg_moran = np.mean(moran_i)
    
    metrics = {
        'temporal_outlier_ratio': temporal_ratio,
        'spatial_outlier_ratio': spatial_ratio,
        'spatiotemporal_outlier_ratio': st_ratio,
        'avg_spatial_autocorrelation': avg_moran,
        'temporal_outliers': temporal_outliers,
        'spatial_outliers': spatial_outliers,
        'spatiotemporal_outliers': spatiotemporal_outliers
    }
    
    return metrics
```

### å¯è§†åŒ–å¯¹æ¯”

```python
def plot_temporal_vs_spatial_noise(metrics, dataset_name):
    """å¯¹æ¯”æ—¶é—´å’Œç©ºé—´å™ªå£°"""
    
    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    
    # 1. æ—¶é—´å¼‚å¸¸å€¼çƒ­å›¾
    ax1 = axes[0, 0]
    im1 = ax1.imshow(metrics['temporal_outliers'].T, 
                     aspect='auto', cmap='Reds', interpolation='nearest')
    ax1.set_title('æ—¶é—´ç»´åº¦å¼‚å¸¸å€¼')
    ax1.set_xlabel('æ—¶é—´æ­¥')
    ax1.set_ylabel('èŠ‚ç‚¹')
    plt.colorbar(im1, ax=ax1)
    
    # 2. ç©ºé—´å¼‚å¸¸å€¼çƒ­å›¾
    ax2 = axes[0, 1]
    im2 = ax2.imshow(metrics['spatial_outliers'].T, 
                     aspect='auto', cmap='Blues', interpolation='nearest')
    ax2.set_title('ç©ºé—´ç»´åº¦å¼‚å¸¸å€¼')
    ax2.set_xlabel('æ—¶é—´æ­¥')
    ax2.set_ylabel('èŠ‚ç‚¹')
    plt.colorbar(im2, ax=ax2)
    
    # 3. æ—¶ç©ºäº¤å‰å¼‚å¸¸å€¼
    ax3 = axes[0, 2]
    im3 = ax3.imshow(metrics['spatiotemporal_outliers'].T, 
                     aspect='auto', cmap='Purples', interpolation='nearest')
    ax3.set_title('æ—¶ç©ºäº¤å‰å¼‚å¸¸å€¼')
    ax3.set_xlabel('æ—¶é—´æ­¥')
    ax3.set_ylabel('èŠ‚ç‚¹')
    plt.colorbar(im3, ax=ax3)
    
    # 4. å¼‚å¸¸å€¼æ¯”ä¾‹å¯¹æ¯”
    ax4 = axes[1, 0]
    categories = ['æ—¶é—´å¼‚å¸¸', 'ç©ºé—´å¼‚å¸¸', 'æ—¶ç©ºäº¤å‰']
    ratios = [
        metrics['temporal_outlier_ratio'],
        metrics['spatial_outlier_ratio'],
        metrics['spatiotemporal_outlier_ratio']
    ]
    bars = ax4.bar(categories, ratios, color=['red', 'blue', 'purple'], alpha=0.7)
    ax4.set_ylabel('å¼‚å¸¸å€¼æ¯”ä¾‹ (%)')
    ax4.set_title('å¼‚å¸¸å€¼ç±»å‹å¯¹æ¯”')
    ax4.grid(True, alpha=0.3, axis='y')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, ratio in zip(bars, ratios):
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height,
                f'{ratio:.2f}%', ha='center', va='bottom')
    
    # 5. æ¯ä¸ªèŠ‚ç‚¹çš„æ—¶é—´vsç©ºé—´å¼‚å¸¸æ•°
    ax5 = axes[1, 1]
    temporal_counts = metrics['temporal_outliers'].sum(axis=0)
    spatial_counts = metrics['spatial_outliers'].sum(axis=0)
    
    ax5.scatter(temporal_counts, spatial_counts, alpha=0.6, s=50)
    ax5.set_xlabel('æ—¶é—´å¼‚å¸¸å€¼æ•°é‡')
    ax5.set_ylabel('ç©ºé—´å¼‚å¸¸å€¼æ•°é‡')
    ax5.set_title('èŠ‚ç‚¹å¼‚å¸¸å€¼åˆ†å¸ƒ')
    ax5.grid(True, alpha=0.3)
    
    # æ·»åŠ å¯¹è§’çº¿
    max_val = max(temporal_counts.max(), spatial_counts.max())
    ax5.plot([0, max_val], [0, max_val], 'r--', alpha=0.5, label='ç›¸ç­‰çº¿')
    ax5.legend()
    
    # 6. ç©ºé—´è‡ªç›¸å…³æ—¶é—´åºåˆ—
    ax6 = axes[1, 2]
    # è¿™é‡Œéœ€è¦å®é™…çš„moran_iæ—¶é—´åºåˆ—
    ax6.set_title('ç©ºé—´è‡ªç›¸å…³æŒ‡æ ‡')
    ax6.set_xlabel('æ—¶é—´æ­¥')
    ax6.set_ylabel("Moran's I")
    ax6.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f'figure/spatiotemporal_noise_{dataset_name}.png', 
                dpi=300, bbox_inches='tight')
    plt.close()
```

---

## 5ï¸âƒ£ å®é™…åº”ç”¨å»ºè®®

### åœºæ™¯1: çº¯æ—¶é—´å™ªå£°
```
æ—¶é—´å¼‚å¸¸: 5.2%
ç©ºé—´å¼‚å¸¸: 0.8%
æ—¶ç©ºäº¤å‰: 0.3%
Moran's I: 0.82
```
**è§£è¯»**: 
- âœ… ç©ºé—´ç»“æ„è‰¯å¥½ï¼ˆé«˜Moran's Iï¼‰
- âš ï¸ æ—¶é—´åºåˆ—æœ‰å™ªå£°
- **å»ºè®®**: ä½¿ç”¨**æ—¶é—´å»å™ª**ï¼ˆconv/attentionï¼‰

### åœºæ™¯2: çº¯ç©ºé—´å™ªå£°
```
æ—¶é—´å¼‚å¸¸: 1.2%
ç©ºé—´å¼‚å¸¸: 6.5%
æ—¶ç©ºäº¤å‰: 0.5%
Moran's I: 0.35
```
**è§£è¯»**:
- âŒ ç©ºé—´ç»“æ„æ··ä¹±ï¼ˆä½Moran's Iï¼‰
- âœ… æ—¶é—´åºåˆ—ç¨³å®š
- **å»ºè®®**: 
  - æ£€æŸ¥ä¼ æ„Ÿå™¨ä½ç½®æ˜¯å¦æ­£ç¡®
  - ä½¿ç”¨**ç©ºé—´å¹³æ»‘**æˆ–**å›¾å·ç§¯**
  - è€ƒè™‘é‡æ–°å­¦ä¹ é‚»æ¥çŸ©é˜µ

### åœºæ™¯3: æ—¶ç©ºè€¦åˆå™ªå£°
```
æ—¶é—´å¼‚å¸¸: 4.8%
ç©ºé—´å¼‚å¸¸: 5.1%
æ—¶ç©ºäº¤å‰: 3.2%  â† é«˜äº¤å‰æ¯”ä¾‹
Moran's I: 0.45
```
**è§£è¯»**:
- âŒ æ—¶ç©ºéƒ½æœ‰é—®é¢˜
- âš ï¸ é«˜äº¤å‰æ¯”ä¾‹è¯´æ˜å™ªå£°åœ¨æ—¶ç©ºä¸Šä¼ æ’­
- **å»ºè®®**: 
  - ä½¿ç”¨**æ—¶ç©ºè”åˆå»å™ª**
  - ç»“åˆattentionå»å™ª + åŠ¨æ€å›¾å­¦ä¹ 
  - è€ƒè™‘æ•°æ®æ¸…æ´—

---

## 6ï¸âƒ£ æ¨¡å‹è®¾è®¡å¯ç¤º

### å¯¹AGPSTçš„å¯ç¤º

åŸºäºæ—¶ç©ºå™ªå£°åˆ†æç»“æœï¼Œä¼˜åŒ–æ¨¡å‹è®¾è®¡ï¼š

```python
# æ ¹æ®å™ªå£°ç±»å‹é€‰æ‹©æ¨¡å—
if temporal_noise_dominant:
    # æ—¶é—´å™ªå£°ä¸ºä¸» â†’ å¼ºåŒ–æ—¶é—´å»å™ª
    use_denoising = True
    denoise_type = 'attention'  # æˆ– 'conv'
    use_advanced_graph = False  # é™æ€å›¾å³å¯

elif spatial_noise_dominant:
    # ç©ºé—´å™ªå£°ä¸ºä¸» â†’ å¼ºåŒ–å›¾å­¦ä¹ 
    use_denoising = False  # æˆ–è½»é‡çº§
    use_advanced_graph = True  # åŠ¨æ€å­¦ä¹ é‚»æ¥å…³ç³»
    graph_heads = 4  # å¤šå¤´å­¦ä¹ ä¸åŒç©ºé—´æ¨¡å¼

elif spatiotemporal_noise:
    # æ—¶ç©ºè€¦åˆå™ªå£° â†’ å…¨åŠ›ä»¥èµ´
    use_denoising = True
    denoise_type = 'attention'
    use_advanced_graph = True
    graph_heads = 4
    # å¯èƒ½è¿˜éœ€è¦é¢å¤–çš„æ—¶ç©ºè”åˆå»å™ªæ¨¡å—
```

### æ–°æ¨¡å—è®¾è®¡æ€è·¯

```python
class SpatioTemporalDenoiser(nn.Module):
    """æ—¶ç©ºè”åˆå»å™ªæ¨¡å—"""
    
    def __init__(self, d_model, num_heads):
        super().__init__()
        
        # æ—¶é—´å»å™ª
        self.temporal_denoise = DenoiseAttention(d_model)
        
        # ç©ºé—´å»å™ªï¼ˆåŸºäºå›¾ç»“æ„ï¼‰
        self.spatial_denoise = DynamicGraphConv(d_model, num_heads)
        
        # èåˆ
        self.fusion = nn.Linear(d_model * 2, d_model)
    
    def forward(self, x, adj_matrix):
        """
        Args:
            x: (B, T, N, C)
            adj_matrix: (N, N) or (B, N, N)
        """
        B, T, N, C = x.shape
        
        # æ—¶é—´å»å™ªï¼šå¯¹æ¯ä¸ªèŠ‚ç‚¹çš„æ—¶é—´åºåˆ—
        x_temp = rearrange(x, 'b t n c -> (b n) t c')
        x_temp_denoised = self.temporal_denoise(x_temp)
        x_temp_denoised = rearrange(x_temp_denoised, '(b n) t c -> b t n c', b=B, n=N)
        
        # ç©ºé—´å»å™ªï¼šå¯¹æ¯ä¸ªæ—¶åˆ»çš„ç©ºé—´åˆ†å¸ƒ
        x_spat = rearrange(x, 'b t n c -> (b t) n c')
        x_spat_denoised = self.spatial_denoise(x_spat, adj_matrix)
        x_spat_denoised = rearrange(x_spat_denoised, '(b t) n c -> b t n c', b=B, t=T)
        
        # èåˆæ—¶é—´å’Œç©ºé—´å»å™ªç»“æœ
        x_fused = torch.cat([x_temp_denoised, x_spat_denoised], dim=-1)
        x_out = self.fusion(x_fused)
        
        return x_out + x  # æ®‹å·®è¿æ¥
```

---

## 7ï¸âƒ£ æ€»ç»“å¯¹æ¯”è¡¨

| ç‰¹æ€§ | æ—¶é—´ç»´åº¦å™ªå£° | ç©ºé—´ç»´åº¦å™ªå£° | æ—¶ç©ºè”åˆ |
|------|-------------|-------------|---------|
| **æ£€æµ‹å¯¹è±¡** | å•èŠ‚ç‚¹æ—¶é—´åºåˆ— | å•æ—¶åˆ»ç©ºé—´åˆ†å¸ƒ | æ—¶ç©ºçŸ©é˜µ |
| **ä¸»è¦æ–¹æ³•** | IQR, SNR, FFT | Moran's I, ç©ºé—´æ¢¯åº¦ | äº¤å‰åˆ†æ |
| **å¸¸è§åŸå› ** | ä¼ æ„Ÿå™¨æ•…éšœã€ç‰¹æ®Šäº‹ä»¶ | ä½ç½®é”™è¯¯ã€åŒºåŸŸäº‹ä»¶ | ç³»ç»Ÿæ€§é—®é¢˜ |
| **å»å™ªç­–ç•¥** | æ—¶é—´å¹³æ»‘ã€å»å™ªæ¨¡å— | ç©ºé—´å¹³æ»‘ã€å›¾å·ç§¯ | æ—¶ç©ºè”åˆå»å™ª |
| **æ¨¡å‹ç»„ä»¶** | Denoising Module | Graph Learning | ä¸¤è€…ç»“åˆ |

---

## ğŸ¯ å¿«é€Ÿå†³ç­–æµç¨‹

```
å™ªå£°åˆ†æ
    â”‚
    â”œâ”€ æ—¶é—´å¼‚å¸¸ > ç©ºé—´å¼‚å¸¸ Ã— 2
    â”‚   â†’ æ—¶é—´å™ªå£°ä¸»å¯¼
    â”‚   â†’ ä½¿ç”¨æ—¶é—´å»å™ªæ¨¡å—
    â”‚
    â”œâ”€ ç©ºé—´å¼‚å¸¸ > æ—¶é—´å¼‚å¸¸ Ã— 2
    â”‚   â†’ ç©ºé—´å™ªå£°ä¸»å¯¼
    â”‚   â†’ ä½¿ç”¨åŠ¨æ€å›¾å­¦ä¹ 
    â”‚
    â””â”€ æ—¶é—´å¼‚å¸¸ â‰ˆ ç©ºé—´å¼‚å¸¸
        â†’ æ—¶ç©ºè€¦åˆå™ªå£°
        â†’ ä½¿ç”¨æ—¶ç©ºè”åˆå»å™ª
```

---

**ä¸‹ä¸€æ­¥**: å®ç°ç©ºé—´ç»´åº¦å™ªå£°åˆ†æè„šæœ¬ `analyze_spatial_noise.py`

